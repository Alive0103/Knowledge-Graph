"""
å®ä½“é“¾æ¥è¯Šæ–­å·¥å…·
ç”¨äºåˆ†æä¸ºä»€ä¹ˆè¯„æµ‹æŒ‡æ ‡è¿™ä¹ˆä½
"""
import pandas as pd
from search_withllm import hybrid_search, generate_prompt_and_sort, normalize_url, clean_link
from tqdm import tqdm
import json

def diagnose_sample_queries(file_path="find.xlsx", sample_size=10):
    """è¯Šæ–­æ ·æœ¬æŸ¥è¯¢ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨"""
    df = pd.read_excel(file_path, header=None)
    queries = df[0].tolist()
    correct_links = df[1].tolist()
    
    print("=" * 80)
    print("å®ä½“é“¾æ¥è¯Šæ–­æŠ¥å‘Š")
    print("=" * 80)
    print(f"æ€»æŸ¥è¯¢æ•°: {len(queries)}")
    print(f"è¯Šæ–­æ ·æœ¬æ•°: {min(sample_size, len(queries))}\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total": 0,
        "found_in_search": 0,  # åœ¨æœç´¢ç»“æœä¸­æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ
        "found_after_rerank": 0,  # é‡æ’åºåæ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ
        "not_found_in_search": 0,  # æœç´¢ç»“æœä¸­æ²¡æœ‰æ­£ç¡®ç­”æ¡ˆ
        "not_found_after_rerank": 0,  # é‡æ’åºåæ²¡æœ‰æ­£ç¡®ç­”æ¡ˆ
        "llm_parse_errors": 0,  # LLMè§£æé”™è¯¯
        "link_format_mismatch": []  # é“¾æ¥æ ¼å¼ä¸åŒ¹é…çš„æ¡ˆä¾‹
    }
    
    # è¯¦ç»†è¯Šæ–­å‰Nä¸ªæŸ¥è¯¢
    for idx in tqdm(range(min(sample_size, len(queries))), desc="è¯Šæ–­ä¸­"):
        query = queries[idx]
        correct_link = str(correct_links[idx])
        stats["total"] += 1
        
        print(f"\n{'='*80}")
        print(f"æŸ¥è¯¢ #{idx+1}: {query}")
        print(f"æ­£ç¡®ç­”æ¡ˆ: {correct_link}")
        print(f"{'='*80}")
        
        try:
            # æ­¥éª¤1: æ‰§è¡Œæœç´¢
            results = hybrid_search(query, top_k=20)
            print(f"\n[æ­¥éª¤1] æœç´¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªå€™é€‰å®ä½“")
            
            # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨æœç´¢ç»“æœä¸­
            found_in_search = False
            search_rank = None
            correct_link_cleaned = clean_link(str(correct_link))
            correct_link_normalized = normalize_url(correct_link_cleaned)
            
            for i, result in enumerate(results):
                result_link = result.get('link', '')
                result_link_cleaned = clean_link(str(result_link))
                result_link_normalized = normalize_url(result_link_cleaned)
                
                # ä½¿ç”¨æ”¹è¿›çš„åŒ¹é…é€»è¾‘ï¼ˆä¸ä¸»ä»£ç ä¸€è‡´ï¼‰
                # 1. å½’ä¸€åŒ–åçš„URLåŒ¹é…ï¼ˆå¤„ç†URLç¼–ç é—®é¢˜ï¼‰
                if correct_link_normalized == result_link_normalized:
                    found_in_search = True
                    search_rank = i + 1
                    print(f"  âœ“ åœ¨æœç´¢ç»“æœç¬¬ {search_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                    print(f"    åŒ¹é…çš„é“¾æ¥: {result_link}")
                    stats["found_in_search"] += 1
                    break
                
                # 2. æ¸…ç†åçš„ç²¾ç¡®åŒ¹é…
                if correct_link_cleaned == result_link_cleaned:
                    found_in_search = True
                    search_rank = i + 1
                    print(f"  âœ“ åœ¨æœç´¢ç»“æœç¬¬ {search_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                    print(f"    åŒ¹é…çš„é“¾æ¥: {result_link}")
                    stats["found_in_search"] += 1
                    break
                
                # 3. åŒå‘å­å­—ç¬¦ä¸²åŒ¹é…
                if correct_link_cleaned in result_link_cleaned or result_link_cleaned in correct_link_cleaned:
                    found_in_search = True
                    search_rank = i + 1
                    print(f"  âœ“ åœ¨æœç´¢ç»“æœç¬¬ {search_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                    print(f"    åŒ¹é…çš„é“¾æ¥: {result_link}")
                    stats["found_in_search"] += 1
                    break
                
                # 4. å½’ä¸€åŒ–åçš„åŒå‘åŒ¹é…
                if correct_link_normalized in result_link_normalized or result_link_normalized in correct_link_normalized:
                    found_in_search = True
                    search_rank = i + 1
                    print(f"  âœ“ åœ¨æœç´¢ç»“æœç¬¬ {search_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                    print(f"    åŒ¹é…çš„é“¾æ¥: {result_link}")
                    stats["found_in_search"] += 1
                    break
            
            if not found_in_search:
                print(f"  âœ— æœç´¢ç»“æœä¸­æœªæ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                stats["not_found_in_search"] += 1
                print(f"  å‰5ä¸ªæœç´¢ç»“æœ:")
                for i, result in enumerate(results[:5], 1):
                    print(f"    {i}. {result.get('label', 'N/A')} -> {result.get('link', 'N/A')}")
            
            # æ­¥éª¤2: LLMé‡æ’åº
            print(f"\n[æ­¥éª¤2] LLMé‡æ’åº...")
            try:
                sorted_links = generate_prompt_and_sort(query, results)
                print(f"  é‡æ’åºåå¾—åˆ° {len(sorted_links)} ä¸ªé“¾æ¥")
                
                # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨é‡æ’åºç»“æœä¸­
                found_after_rerank = False
                rerank_rank = None
                correct_link_cleaned = clean_link(str(correct_link))
                correct_link_normalized = normalize_url(correct_link_cleaned)
                
                for i, link in enumerate(sorted_links):
                    link_cleaned = clean_link(str(link))
                    link_normalized = normalize_url(link_cleaned)
                    
                    # ä½¿ç”¨æ”¹è¿›çš„åŒ¹é…é€»è¾‘ï¼ˆä¸ä¸»ä»£ç ä¸€è‡´ï¼‰
                    # 1. å½’ä¸€åŒ–åçš„URLåŒ¹é…ï¼ˆå¤„ç†URLç¼–ç é—®é¢˜ï¼‰
                    if correct_link_normalized == link_normalized:
                        found_after_rerank = True
                        rerank_rank = i + 1
                        print(f"  âœ“ é‡æ’åºåç¬¬ {rerank_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                        print(f"    åŒ¹é…çš„é“¾æ¥: {link}")
                        stats["found_after_rerank"] += 1
                        break
                    
                    # 2. æ¸…ç†åçš„ç²¾ç¡®åŒ¹é…
                    if correct_link_cleaned == link_cleaned:
                        found_after_rerank = True
                        rerank_rank = i + 1
                        print(f"  âœ“ é‡æ’åºåç¬¬ {rerank_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                        print(f"    åŒ¹é…çš„é“¾æ¥: {link}")
                        stats["found_after_rerank"] += 1
                        break
                    
                    # 3. åŒå‘å­å­—ç¬¦ä¸²åŒ¹é…
                    if correct_link_cleaned in link_cleaned or link_cleaned in correct_link_cleaned:
                        found_after_rerank = True
                        rerank_rank = i + 1
                        print(f"  âœ“ é‡æ’åºåç¬¬ {rerank_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                        print(f"    åŒ¹é…çš„é“¾æ¥: {link}")
                        stats["found_after_rerank"] += 1
                        break
                    
                    # 4. å½’ä¸€åŒ–åçš„åŒå‘åŒ¹é…
                    if correct_link_normalized in link_normalized or link_normalized in correct_link_normalized:
                        found_after_rerank = True
                        rerank_rank = i + 1
                        print(f"  âœ“ é‡æ’åºåç¬¬ {rerank_rank} ä½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                        print(f"    åŒ¹é…çš„é“¾æ¥: {link}")
                        stats["found_after_rerank"] += 1
                        break
                
                if not found_after_rerank:
                    print(f"  âœ— é‡æ’åºåæœªæ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ")
                    stats["not_found_after_rerank"] += 1
                    print(f"  å‰5ä¸ªé‡æ’åºç»“æœ:")
                    for i, link in enumerate(sorted_links[:5], 1):
                        print(f"    {i}. {link}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¼å¼é—®é¢˜
                    print(f"\n  é“¾æ¥æ ¼å¼æ£€æŸ¥:")
                    print(f"    æ­£ç¡®ç­”æ¡ˆæ ¼å¼: '{correct_link}' (é•¿åº¦: {len(correct_link)})")
                    print(f"    å½’ä¸€åŒ–å: '{correct_link_normalized}'")
                    print(f"    é‡æ’åºç»“æœä¸­çš„é“¾æ¥ç¤ºä¾‹:")
                    for i, link in enumerate(sorted_links[:3], 1):
                        link_normalized = normalize_url(clean_link(str(link)))
                        print(f"      {i}. '{link}' (é•¿åº¦: {len(link)})")
                        print(f"         å½’ä¸€åŒ–å: '{link_normalized}'")
                        # ä½¿ç”¨å½’ä¸€åŒ–åçš„URLè¿›è¡Œæ¯”è¾ƒ
                        if correct_link_normalized != link_normalized:
                            print(f"        âš  å½’ä¸€åŒ–åä»ä¸åŒ¹é…!")
                            if idx < 5:  # åªè®°å½•å‰5ä¸ªä¸åŒ¹é…çš„æ¡ˆä¾‹
                                stats["link_format_mismatch"].append({
                                    "query": query,
                                    "correct": correct_link,
                                    "correct_normalized": correct_link_normalized,
                                    "got": link,
                                    "got_normalized": link_normalized
                                })
                        else:
                            print(f"        âœ“ å½’ä¸€åŒ–ååŒ¹é…!")
                
                # å¯¹æ¯”æœç´¢å’Œé‡æ’åºçš„æ’åå˜åŒ–
                if found_in_search and found_after_rerank:
                    if search_rank != rerank_rank:
                        print(f"\n  ğŸ“Š æ’åå˜åŒ–: æœç´¢ç¬¬{search_rank}ä½ -> é‡æ’åºç¬¬{rerank_rank}ä½")
                        if rerank_rank > search_rank:
                            print(f"     âš  LLMé‡æ’åºæŠŠæ­£ç¡®ç­”æ¡ˆæ’åˆ°äº†æ›´åé¢!")
                    else:
                        print(f"\n  âœ“ æ’åæœªå˜åŒ–: éƒ½æ˜¯ç¬¬{search_rank}ä½")
                
            except Exception as e:
                print(f"  âœ— LLMé‡æ’åºå¤±è´¥: {e}")
                stats["llm_parse_errors"] += 1
                import traceback
                traceback.print_exc()
                
        except Exception as e:
            print(f"\n  âœ— å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    # è¾“å‡ºç»Ÿè®¡æŠ¥å‘Š
    print(f"\n\n{'='*80}")
    print("è¯Šæ–­ç»Ÿè®¡æŠ¥å‘Š")
    print(f"{'='*80}")
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total']}")
    print(f"åœ¨æœç´¢ç»“æœä¸­æ‰¾åˆ°: {stats['found_in_search']} ({stats['found_in_search']/stats['total']*100:.1f}%)")
    print(f"é‡æ’åºåæ‰¾åˆ°: {stats['found_after_rerank']} ({stats['found_after_rerank']/stats['total']*100:.1f}%)")
    print(f"æœç´¢ç»“æœä¸­æœªæ‰¾åˆ°: {stats['not_found_in_search']} ({stats['not_found_in_search']/stats['total']*100:.1f}%)")
    print(f"é‡æ’åºåæœªæ‰¾åˆ°: {stats['not_found_after_rerank']} ({stats['not_found_after_rerank']/stats['total']*100:.1f}%)")
    print(f"LLMè§£æé”™è¯¯: {stats['llm_parse_errors']} ({stats['llm_parse_errors']/stats['total']*100:.1f}%)")
    
    if stats['link_format_mismatch']:
        print(f"\né“¾æ¥æ ¼å¼ä¸åŒ¹é…æ¡ˆä¾‹ (å‰5ä¸ª):")
        for case in stats['link_format_mismatch'][:5]:
            print(f"  æŸ¥è¯¢: {case['query']}")
            print(f"    æ­£ç¡®ç­”æ¡ˆ: '{case['correct']}'")
            print(f"    å®é™…å¾—åˆ°: '{case['got']}'")
    
    # åˆ†æå¯èƒ½çš„é—®é¢˜
    print(f"\n{'='*80}")
    print("é—®é¢˜åˆ†æ")
    print(f"{'='*80}")
    
    if stats['not_found_in_search'] / stats['total'] > 0.5:
        print("âš  ä¸»è¦é—®é¢˜: æœç´¢ç»“æœä¸­æ‰¾ä¸åˆ°æ­£ç¡®ç­”æ¡ˆ")
        print("  å»ºè®®: æ£€æŸ¥Elasticsearchç´¢å¼•æ•°æ®ï¼Œç¡®è®¤æ­£ç¡®ç­”æ¡ˆæ˜¯å¦åœ¨çŸ¥è¯†åº“ä¸­")
    
    if stats['not_found_after_rerank'] > stats['not_found_in_search']:
        print("âš  ä¸»è¦é—®é¢˜: LLMé‡æ’åºå¯¼è‡´æ­£ç¡®ç­”æ¡ˆä¸¢å¤±")
        print("  å»ºè®®: æ£€æŸ¥LLMè¿”å›çš„é“¾æ¥æ ¼å¼ï¼Œç¡®ä¿ä¸æ­£ç¡®ç­”æ¡ˆæ ¼å¼ä¸€è‡´")
    
    if stats['llm_parse_errors'] / stats['total'] > 0.1:
        print("âš  ä¸»è¦é—®é¢˜: LLMè§£æé”™è¯¯ç‡è¾ƒé«˜")
        print("  å»ºè®®: æ£€æŸ¥LLM promptï¼Œç¡®ä¿è¿”å›æ ¼å¼ç¨³å®š")
    
    if stats['found_after_rerank'] / stats['total'] < 0.1:
        print("âš  ä¸»è¦é—®é¢˜: æ•´ä½“å‡†ç¡®ç‡è¿‡ä½")
        print("  å»ºè®®: æ£€æŸ¥æœç´¢ç­–ç•¥å’ŒLLMé‡æ’åºé€»è¾‘")
    
    print(f"\n{'='*80}")

if __name__ == "__main__":
    diagnose_sample_queries(sample_size=20)  # è¯Šæ–­å‰20ä¸ªæŸ¥è¯¢

