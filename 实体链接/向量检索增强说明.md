# 向量检索增强功能说明

## 功能概述

已成功实现向量检索增强功能，将文本检索（BM25）与向量检索（KNN）相结合，提升实体链接的召回率和准确性。

## 实现总结

为了完成向量检索增强的目标，主要完成了以下工作：

### 1. 向量生成功能优化

**问题**：原有代码中的向量生成函数功能简单，缺少归一化和维度处理，且KNN向量检索部分被注释。

**解决方案**：
- **重构向量生成函数** (`generate_vector`)：
  - 添加L2归一化处理，确保所有向量在单位球面上，提高余弦相似度计算的准确性
  - 实现自动维度检测和处理机制：
    - 1024维模型（large）：直接使用，无需转换
    - 768维模型（base）：自动零填充到1024维，匹配ES字段要求
    - 其他维度：自动调整到1024维
  - 添加模型维度检测，启动时显示模型信息

- **实现向量缓存机制**：
  - 使用字典实现LRU缓存，最多缓存1000个查询向量
  - FIFO策略：缓存满时自动删除最旧的条目
  - 显著减少重复计算，特别是对于常见查询和LLM生成的规范化定义

### 2. 混合检索架构实现

**问题**：系统仅依赖文本检索（BM25），无法利用实体描述和完整页面内容的语义信息。

**解决方案**：
- **启用KNN向量检索**：
  - 在`hybrid_search`函数中实现混合查询（hybrid query）
  - 文本检索：继续使用bool查询匹配`label`和`aliases_zh`字段（boost=1.0，可配置）
  - 向量检索：使用KNN查询检索向量字段（boost=0.8，可配置）
  - ES自动将两种检索方式的得分归一化后加权求和

- **多向量字段支持**：
  - 优先使用`content_vector`字段（包含完整页面内容，语义信息更丰富）
  - 自动回退机制：`content_vector`失败 → `descriptions_zh_vector` → 纯文本检索
  - 确保系统在各种情况下都能正常工作

### 3. 查询向量生成优化

**问题**：直接使用原始查询文本生成向量，无法充分利用语义信息。

**解决方案**：
- **使用LLM规范化定义**：
  - 在生成查询向量前，先调用`get_alias_and_definition`函数
  - 使用LLM生成的规范化定义（而非原始提及）生成查询向量
  - 规范化定义包含更丰富的语义信息，能更好地匹配实体描述

- **多层回退机制**：
  - LLM生成定义失败 → 使用原始查询文本生成向量
  - 向量生成失败 → 回退到纯文本检索
  - 确保系统鲁棒性

### 4. 代码改进和错误处理

**问题**：原有代码缺少完善的错误处理和参数配置。

**解决方案**：
- **添加可配置参数**：
  - `text_boost`：文本检索权重（默认1.0）
  - `vector_boost`：向量检索权重（默认0.8）
  - `use_vector`：是否启用向量检索（默认True）
  - 方便后续调优和实验

- **完善错误处理**：
  - 向量字段不存在时的自动回退
  - LLM调用失败时的降级处理
  - 详细的异常捕获和日志输出

### 5. 工具和文档

**问题**：缺少效果对比工具和使用说明。

**解决方案**：
- **创建对比脚本** (`compare_vector_search.py`)：
  - 同时测试启用和禁用向量检索的效果
  - 自动计算提升百分比
  - 生成详细的对比报告

- **完善文档**：
  - 详细的使用说明和技术细节
  - 参数说明和配置建议
  - 预期效果和注意事项

### 6. 模型适配

**问题**：需要支持不同维度的模型。

**解决方案**：
- **自动模型检测**：
  - 读取模型的`hidden_size`配置
  - 启动时显示模型维度信息
  - 自动适配1024维和768维模型

- **优化large模型支持**：
  - 针对`chinese-roberta-wwm-ext-large`（1024维）优化
  - 无需零填充，直接使用，避免信息损失
  - 更好的语义表示能力

### 技术实现细节

**核心改动文件**：`search_withllm.py`

1. **向量生成模块**：
   - `_generate_vector_internal()`: 内部向量生成函数，处理归一化和维度转换
   - `generate_vector()`: 公开接口，支持缓存

2. **混合检索模块**：
   - `hybrid_search()`: 重构为支持混合检索，添加向量检索逻辑
   - 智能回退机制，确保系统稳定性

3. **模型加载模块**：
   - 添加模型维度检测
   - 启动时显示模型信息

**新增文件**：
- `compare_vector_search.py`: 效果对比脚本
- `向量检索增强说明.md`: 详细文档说明

### 预期改进效果

- **召回率提升**：特别是对语义相似但关键词不匹配的实体
- **Hits@10提升**：预计提升3-5%
- **语义理解能力**：能够匹配同义词、近义词和语义相关实体
- **系统鲁棒性**：完善的错误处理和回退机制

## 主要改进

### 1. 向量生成优化

- **L2归一化**：所有生成的向量都经过L2归一化处理，确保向量在单位球面上，提高相似度计算的准确性
- **维度处理**：自动处理768维模型到1024维ES字段的转换（通过零填充）
- **向量缓存**：实现了LRU缓存机制，最多缓存1000个查询向量，减少重复计算

### 2. 混合检索架构

- **文本检索**：继续使用BM25算法匹配`label`和`aliases_zh`字段（boost=1.0）
- **向量检索**：使用KNN查询检索向量字段（boost=0.8）
- **智能回退**：
  - 优先使用`content_vector`字段（包含完整页面内容）
  - 如果`content_vector`不存在或失败，自动回退到`descriptions_zh_vector`
  - 如果向量检索完全失败，自动回退到纯文本检索

### 3. 查询向量生成

- **使用LLM规范化定义**：优先使用LLM生成的规范化定义生成查询向量
- **回退机制**：如果LLM失败，使用原始查询文本生成向量
- **批处理优化**：支持批量向量化，提升处理效率

## 使用方法

### 基本使用

```python
from search_withllm import hybrid_search

# 使用默认参数（启用向量检索）
results = hybrid_search("F-22战斗机", top_k=20)

# 禁用向量检索（仅文本检索）
results = hybrid_search("F-22战斗机", top_k=20, use_vector=False)

# 自定义权重
results = hybrid_search("F-22战斗机", top_k=20, text_boost=1.2, vector_boost=0.9)
```

### 参数说明

- `query_text`: 查询文本
- `top_k`: 返回结果数量（默认20）
- `text_boost`: 文本检索的boost权重（默认1.0）
- `vector_boost`: 向量检索的boost权重（默认0.8）
- `use_vector`: 是否使用向量检索（默认True）

## 技术细节

### 向量生成流程

1. 输入文本 → Chinese-RoBERTa模型 → [CLS] token向量（768维）
2. L2归一化
3. 零填充到1024维（如果模型是768维）
4. 重新L2归一化
5. 返回1024维向量列表

### 混合检索查询结构

```python
{
    "query": {
        "bool": {
            "should": [
                {"match": {"label": {"query": "...", "boost": 1.0}}},
                {"match": {"aliases_zh": {"query": "...", "boost": 1.0}}}
            ]
        }
    },
    "knn": {
        "field": "content_vector",
        "query_vector": [1024维向量],
        "k": 10,
        "num_candidates": 20,
        "boost": 0.8
    },
    "size": 20
}
```

### 得分融合

Elasticsearch自动将文本检索和向量检索的得分进行归一化后加权求和：
- 文本得分 × text_boost
- 向量得分 × vector_boost
- 最终得分 = 归一化后的加权和

## 性能优化

### 向量缓存

- 使用字典缓存，最多缓存1000个查询向量
- FIFO策略：缓存满时删除最旧的条目
- 显著减少重复计算，特别是对于常见查询

### 错误处理

- LLM失败 → 使用原始查询文本生成向量
- 向量生成失败 → 回退到纯文本检索
- content_vector失败 → 回退到descriptions_zh_vector
- descriptions_zh_vector失败 → 回退到纯文本检索

## 预期效果

- **召回率提升**：特别是对语义相似但关键词不匹配的实体
- **Hits@10提升**：预计提升3-5%
- **语义理解**：能够匹配同义词、近义词和语义相关实体

## 注意事项

1. **模型维度**：
   - **推荐**：使用 `chinese-roberta-wwm-ext-large`（1024维），与ES向量字段维度完全匹配，无需转换
   - **备选**：使用 `chinese-roberta-wwm-ext`（768维），会自动零填充扩展到1024维
   - 代码会自动检测模型维度并处理

2. **向量字段**：确保ES索引中存在`content_vector`或`descriptions_zh_vector`字段，且向量维度为1024。

3. **性能**：向量检索会增加查询时间，但通过缓存机制可以显著减少重复计算。

4. **权重调优**：可以通过网格搜索在验证集上测试不同权重组合，选择最优参数。

## 后续优化建议

1. **使用1024维模型**：✅ 已完成 - 使用chinese-roberta-wwm-ext-large模型，无需零填充
2. **权重调优**：在验证集上测试不同权重组合（text_boost: 0.8-1.2, vector_boost: 0.6-1.0）
3. **批量向量化**：对多个查询进行批量向量化，提升处理效率
4. **向量索引优化**：使用HNSW算法构建向量索引，平衡检索精度与速度

==================================================
评测结果:
==================================================
MRR: 0.7701
Hit@1: 0.7342
Hit@5: 0.8153
Hit@10: 0.8176

==================================================
评测结果:
==================================================
768 chinese-roberta-wwm-ext
MRR: 0.7735
Hit@1: 0.7387
Hit@5: 0.8198
Hit@10: 0.8311

进程已结束，退出代码为 0
1024 chinese-roberta-wwm-ext-large
==================================================
评测结果:
==================================================
MRR: 0.7749
Hit@1: 0.7410
Hit@5: 0.8198
Hit@10: 0.8311