"""
æ£€æŸ¥ESä¸­å‘é‡æ•°æ®çš„å®Œæ•´æ€§
ç»Ÿè®¡æœ‰å¤šå°‘æ–‡æ¡£åŒ…å«å‘é‡å­—æ®µ
å¹¶æµ‹è¯•å‘é‡æœç´¢å’Œæ–‡æœ¬æœç´¢åŠŸèƒ½
"""
from es_client import es
import json
import torch
from transformers import BertTokenizer, BertModel

# åˆå§‹åŒ–BERTæ¨¡å‹ï¼ˆç”¨äºç”ŸæˆæŸ¥è¯¢å‘é‡ï¼‰
model_name = './model/chinese-roberta-wwm-ext-large'
try:
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertModel.from_pretrained(model_name)
    model.eval()
    print("âœ“ BERTæ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âœ— BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    tokenizer = None
    model = None

def generate_vector(text):
    """ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆä¸search_withllm.pyä¿æŒä¸€è‡´ï¼‰"""
    if text and text.strip() and tokenizer and model:
        try:
            import numpy as np
            inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)
            with torch.no_grad():
                outputs = model(**inputs)
            vector = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
            
            # L2å½’ä¸€åŒ–ï¼ˆå¯¹ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé‡è¦ï¼‰
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = vector / norm
            
            # ç¡®ä¿ç»´åº¦æ˜¯1024ï¼ˆè™½ç„¶largeæ¨¡å‹å·²ç»æ˜¯1024ç»´ï¼Œä½†ä¿æŒä¸€è‡´æ€§ï¼‰
            vector_dim = len(vector)
            target_dim = 1024
            if vector_dim != target_dim:
                if vector_dim < target_dim:
                    vector = np.pad(vector, (0, target_dim - vector_dim), 'constant', constant_values=0)
                    # é‡æ–°å½’ä¸€åŒ–
                    norm = np.linalg.norm(vector)
                    if norm > 0:
                        vector = vector / norm
                else:
                    vector = vector[:target_dim]
                    # é‡æ–°å½’ä¸€åŒ–
                    norm = np.linalg.norm(vector)
                    if norm > 0:
                        vector = vector / norm
            
            return vector.tolist()
        except Exception as e:
            print(f"å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            return None
    return None

def test_vector_search(index_name, query_text, top_k=5):
    """æµ‹è¯•å‘é‡æœç´¢åŠŸèƒ½"""
    print(f"\nğŸ” æµ‹è¯•å‘é‡æœç´¢: '{query_text}'")
    print("-" * 50)

    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_vector = generate_vector(query_text)
    if not query_vector:
        print("âŒ æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡")
        return

    print(f"æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_vector)}")

    try:
        # ä½¿ç”¨KNNæœç´¢
        knn_query = {
            "knn": {
                "field": "descriptions_zh_vector",
                "query_vector": query_vector,
                "k": top_k,
                "num_candidates": 50
            }
        }

        response = es.search(
            index=index_name,
            body={
                "size": top_k,
                "_source": ["label", "descriptions_zh", "link"],
                "knn": knn_query["knn"]
            }
        )

        hits = response['hits']['hits']
        total_hits = response['hits']['total']['value']

        print(f"âœ“ KNNæœç´¢æˆåŠŸ! æ‰¾åˆ° {total_hits} ä¸ªç›¸å…³æ–‡æ¡£")

        for i, hit in enumerate(hits, 1):
            score = hit['_score']
            source = hit['_source']
            label = source.get('label', 'N/A')
            desc = source.get('descriptions_zh', '')[:100] + "..." if len(source.get('descriptions_zh', '')) > 100 else source.get('descriptions_zh', '')
            link = source.get('link', '')

            print(f"\n{i}. ç›¸ä¼¼åº¦: {score:.4f}")
            print(f"   æ ‡é¢˜: {label}")
            print(f"   æè¿°: {desc}")
            if link:
                print(f"   é“¾æ¥: {link}")

    except Exception as e:
        print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šæ£€æŸ¥æ˜¯å¦æ”¯æŒè„šæœ¬æŸ¥è¯¢
        try:
            print("å°è¯•å¤‡ç”¨æœç´¢æ–¹æ³•...")
            # ç®€å•çš„åŒ¹é…æŸ¥è¯¢ä½œä¸ºå¤‡ç”¨
            backup_response = es.search(
                index=index_name,
                body={
                    "size": top_k,
                    "query": {
                        "match": {
                            "descriptions_zh": query_text
                        }
                    },
                    "_source": ["label", "descriptions_zh"]
                }
            )

            backup_hits = backup_response['hits']['hits']
            print(f"å¤‡ç”¨æœç´¢æ‰¾åˆ° {len(backup_hits)} ä¸ªæ–‡æ¡£")
            for i, hit in enumerate(backup_hits, 1):
                source = hit['_source']
                print(f"  {i}. æ ‡é¢˜: {source.get('label', 'N/A')}")

        except Exception as e2:
            print(f"å¤‡ç”¨æœç´¢ä¹Ÿå¤±è´¥: {e2}")

def test_text_search(index_name, query_text, top_k=5):
    """æµ‹è¯•æ–‡æœ¬æœç´¢åŠŸèƒ½"""
    print(f"\nğŸ” æµ‹è¯•æ–‡æœ¬æœç´¢: '{query_text}'")
    print("-" * 50)

    try:
        # å¤šå­—æ®µæ–‡æœ¬æœç´¢
        text_query = {
            "multi_match": {
                "query": query_text,
                "fields": [
                    "label^3",           # æ ‡é¢˜å­—æ®µæƒé‡æ›´é«˜
                    "descriptions_zh^2", # æè¿°å­—æ®µä¸­ç­‰æƒé‡
                    "aliases_zh^2",      # åˆ«åå­—æ®µä¸­ç­‰æƒé‡
                    "content"           # å†…å®¹å­—æ®µé»˜è®¤æƒé‡
                ],
                "type": "best_fields"
            }
        }

        response = es.search(
            index=index_name,
            body={
                "size": top_k,
                "query": text_query,
                "_source": ["label", "descriptions_zh", "score"],
                "highlight": {
                    "fields": {
                        "descriptions_zh": {},
                        "label": {}
                    }
                }
            }
        )

        hits = response['hits']['hits']
        total_hits = response['hits']['total']['value']

        print(f"âœ“ æ–‡æœ¬æœç´¢æˆåŠŸ! æ‰¾åˆ° {total_hits} ä¸ªç›¸å…³æ–‡æ¡£")

        for i, hit in enumerate(hits, 1):
            score = hit['_score']
            source = hit['_source']
            label = source.get('label', 'N/A')
            desc = source.get('descriptions_zh', '')[:100] + "..." if len(source.get('descriptions_zh', '')) > 100 else source.get('descriptions_zh', '')

            print(f"\n{i}. ç›¸å…³åº¦: {score:.4f}")
            print(f"   æ ‡é¢˜: {label}")
            print(f"   æè¿°: {desc}")

            # æ˜¾ç¤ºé«˜äº®ç»“æœ
            if 'highlight' in hit:
                highlights = hit['highlight']
                for field, highlights_list in highlights.items():
                    for hl in highlights_list[:2]:  # æ˜¾ç¤ºå‰2ä¸ªé«˜äº®ç‰‡æ®µ
                        print(f"   é«˜äº®({field}): {hl}")

    except Exception as e:
        print(f"âŒ æ–‡æœ¬æœç´¢å¤±è´¥: {e}")

def test_hybrid_search(index_name, query_text, top_k=5):
    """æµ‹è¯•æ··åˆæœç´¢ï¼ˆå‘é‡+æ–‡æœ¬ï¼‰"""
    print(f"\nğŸ” æµ‹è¯•æ··åˆæœç´¢: '{query_text}'")
    print("-" * 50)

    query_vector = generate_vector(query_text)
    if not query_vector:
        print("âŒ æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼Œè·³è¿‡æ··åˆæœç´¢")
        return

    try:
        # æ··åˆæœç´¢ï¼šKNN + æ–‡æœ¬è¿‡æ»¤
        hybrid_query = {
            "knn": {
                "field": "descriptions_zh_vector",
                "query_vector": query_vector,
                "k": top_k * 2,  # è·å–æ›´å¤šå€™é€‰
                "num_candidates": 100,
                "filter": {
                    "match": {
                        "descriptions_zh": query_text
                    }
                }
            }
        }

        response = es.search(
            index=index_name,
            body={
                "size": top_k,
                "_source": ["label", "descriptions_zh"],
                "knn": hybrid_query["knn"]
            }
        )

        hits = response['hits']['hits']
        print(f"âœ“ æ··åˆæœç´¢æˆåŠŸ! æ‰¾åˆ° {len(hits)} ä¸ªç›¸å…³æ–‡æ¡£")

        for i, hit in enumerate(hits, 1):
            score = hit['_score']
            source = hit['_source']
            print(f"  {i}. ç›¸ä¼¼åº¦: {score:.4f}, æ ‡é¢˜: {source.get('label', 'N/A')}")

    except Exception as e:
        print(f"âŒ æ··åˆæœç´¢å¤±è´¥: {e}")

def check_vector_data():
    """æ£€æŸ¥ESä¸­å‘é‡æ•°æ®çš„å®Œæ•´æ€§"""
    index_name = "data2"

    print("=" * 60)
    print("æ£€æŸ¥ESä¸­å‘é‡æ•°æ®çš„å®Œæ•´æ€§")
    print("=" * 60)

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
    if not es.indices.exists(index=index_name):
        print(f"âŒ ç´¢å¼• {index_name} ä¸å­˜åœ¨")
        return

    # è·å–æ€»æ–‡æ¡£æ•°
    total_count = es.count(index=index_name)["count"]
    print(f"\nç´¢å¼• '{index_name}' æ€»æ–‡æ¡£æ•°: {total_count}")

    # ç»Ÿè®¡æœ‰å‘é‡çš„æ–‡æ¡£æ•°
    print("\næ­£åœ¨ç»Ÿè®¡å‘é‡å­—æ®µæ•°æ®...")

    vector_fields = ["descriptions_zh_vector", "descriptions_en_vector", "content_vector"]
    field_stats = {}

    for field in vector_fields:
        try:
            query = {
                "query": {
                    "exists": {"field": field}
                },
                "size": 0
            }
            result = es.search(index=index_name, body=query)
            count = result["hits"]["total"]["value"]
            field_stats[field] = count
            print(f"âœ“ åŒ…å« {field} çš„æ–‡æ¡£æ•°: {count}")
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢ {field} å¤±è´¥: {e}")
            field_stats[field] = 0

    # ç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 60)
    print("ç»Ÿè®¡ç»“æœ:")
    print("=" * 60)
    print(f"æ€»æ–‡æ¡£æ•°: {total_count}")
    for field, count in field_stats.items():
        percentage = (count / total_count * 100) if total_count > 0 else 0
        print(f"æœ‰ {field} çš„æ–‡æ¡£: {count} ({percentage:.2f}%)")

    # æ£€æŸ¥å‡ ä¸ªæ ·æœ¬æ–‡æ¡£
    print("\n" + "=" * 60)
    print("æ ·æœ¬æ–‡æ¡£æ£€æŸ¥:")
    print("=" * 60)

    sample_query = {
        "query": {
            "exists": {"field": "descriptions_zh_vector"}
        },
        "size": 3
    }

    try:
        sample_result = es.search(index=index_name, body=sample_query)
        hits = sample_result['hits']['hits']

        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            label = source.get('label', 'N/A')

            has_zh_vec = "descriptions_zh_vector" in source and source["descriptions_zh_vector"]
            vec_dims = len(source["descriptions_zh_vector"]) if has_zh_vec and isinstance(source["descriptions_zh_vector"], list) else 0

            print(f"\næ ·æœ¬æ–‡æ¡£ {i}: {label}")
            print(f"  descriptions_zh_vector: {'âœ“' if has_zh_vec else 'âŒ'} (ç»´åº¦: {vec_dims})")

    except Exception as e:
        print(f"âŒ è·å–æ ·æœ¬æ–‡æ¡£å¤±è´¥: {e}")

    # æµ‹è¯•æœç´¢åŠŸèƒ½
    if field_stats["descriptions_zh_vector"] > 0:
        print("\n" + "=" * 60)
        print("æœç´¢åŠŸèƒ½æµ‹è¯•:")
        print("=" * 60)

        test_queries = [
            "å†›äº‹è£…å¤‡",
            "æˆ˜æ–—æœº",
            "èˆªç©ºæ¯èˆ°"
        ]

        for query in test_queries:
            # æµ‹è¯•å‘é‡æœç´¢
            test_vector_search(index_name, query)

            # æµ‹è¯•æ–‡æœ¬æœç´¢
            test_text_search(index_name, query)

            # æµ‹è¯•æ··åˆæœç´¢
            test_hybrid_search(index_name, query)

            print("\n" + "="*50)

    # è¯Šæ–­å»ºè®®
    print("\n" + "=" * 60)
    print("è¯Šæ–­å»ºè®®:")
    print("=" * 60)

    if all(count == 0 for count in field_stats.values()):
        print("âŒ é—®é¢˜ç¡®è®¤: ESä¸­æ²¡æœ‰ä»»ä½•å‘é‡æ•°æ®ï¼")
        print("\nè§£å†³æ–¹æ¡ˆ:")
        print("1. è¿è¡Œå‘é‡ç”Ÿæˆå’Œå¯¼å…¥è„šæœ¬")
        print("2. æ£€æŸ¥å‘é‡ç”Ÿæˆä»£ç æ˜¯å¦æ­£ç¡®")
    elif field_stats["descriptions_zh_vector"] < total_count * 0.5:
        print("âš  è­¦å‘Š: å¤§éƒ¨åˆ†æ–‡æ¡£ç¼ºå°‘å‘é‡æ•°æ®")
        print("å»ºè®®é‡æ–°è¿è¡Œå‘é‡ç”Ÿæˆè„šæœ¬è¡¥å……å‘é‡æ•°æ®")
    else:
        print("âœ“ å‘é‡æ•°æ®å®Œæ•´æ€§è‰¯å¥½")
        print("âœ“ æœç´¢åŠŸèƒ½æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    check_vector_data()