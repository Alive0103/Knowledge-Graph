# 检索方案对比说明

> **注意**: 这是检索系统的详细技术文档。快速开始请参考 [主README.md](./README.md)

## 📚 文档导航

- [主README.md](./README.md) - 系统总览和快速开始
- [NER训练文档](./ner/训练与使用文档.md) - NER模型详细文档
- [本文档](#) - 检索方案详细对比

---

## 📊 对比方案总览

系统支持**5种检索方案**进行对比评估，每种方案使用不同的检索策略和排序方法。

| 方案 | 模式名称 | 向量检索 | ES文本搜索 | LLM判断 | 特点 |
|------|---------|---------|-----------|---------|------|
| 方案1 | `vector_only` | ✅ | ❌ | ❌ | 纯向量检索，速度快 |
| 方案2 | `es_text_only` | ❌ | ✅ | ❌ | 纯文本搜索，不依赖向量 |
| 方案3 | `llm_only` | ❌ | ✅ | ✅ | 纯LLM语义判断 |
| 方案4 | `vector_with_llm_always` | ✅ | ❌ | ✅ | 始终使用LLM重排序 |
| 方案5 | `vector_with_llm` | ✅ | ✅ | ✅ | 智能混合模式（推荐） |

---

## 🔍 各方案详细说明

### 方案1: 纯向量检索 (`vector_only`)

**工作流程**:
1. 使用微调后的NER模型生成查询向量（1024维）
2. 在ES中进行KNN向量检索（检索所有7个向量字段）
3. 按ES返回的向量相似度分数排序
4. 直接返回排序结果，不使用LLM

**优点**:
- ⚡ 速度快，无需调用LLM API
- 💰 成本低，不消耗LLM token
- 📊 结果稳定，不受LLM响应影响

**缺点**:
- 🎯 可能受向量质量影响，语义理解有限
- 📉 对于复杂查询可能效果不佳

**适用场景**:
- 大规模批量检索
- 对速度要求高的场景
- 查询词与实体名称高度匹配的情况

---

### 方案2: 纯ES文本搜索 (`es_text_only`)

**工作流程**:
1. 使用ES的`multi_match`查询进行文本搜索
2. 搜索字段：`label`（权重3）、`aliases_zh`（权重2）、`aliases_en`（权重2）、`descriptions_zh`、`descriptions_en`
3. 按ES文本匹配分数排序
4. 不使用向量，不使用LLM

**优点**:
- ⚡ 速度快，无需向量生成和LLM调用
- 💰 成本最低
- 🔍 对关键词匹配效果好

**缺点**:
- 📉 语义理解能力弱
- 🎯 对同义词、近义词处理不佳
- 📊 可能受文本匹配算法限制

**适用场景**:
- 查询词与实体名称完全匹配的情况
- 需要快速检索且对精度要求不高的场景
- 作为baseline对比

---

### 方案3: 纯LLM判断 (`llm_only`)

**工作流程**:
1. 使用ES文本搜索获取候选（`multi_match`查询，获取30个候选）
2. 使用LLM获取查询词的别名、定义和详细描述
3. 使用LLM直接判断查询词与每个候选描述的语义匹配度
4. 按LLM判断的匹配度排序
5. 不进行向量检索

**优点**:
- 🧠 语义理解能力强
- 🎯 能处理同义词、近义词
- 📊 不依赖向量质量

**缺点**:
- ⏱️ 速度较慢（需要调用LLM API）
- 💰 成本较高（消耗LLM token）
- 🔄 可能受LLM响应稳定性影响

**适用场景**:
- 查询词与实体名称差异较大的情况
- 需要深度语义理解的任务
- 向量检索效果不佳时的备选方案

---

### 方案4: 向量+LLM（始终重排序）(`vector_with_llm_always`)

**工作流程**:
1. 使用微调后的NER模型生成查询向量
2. 在ES中进行KNN向量检索（获取30个候选）
3. **始终**使用LLM对向量检索结果进行重排序
4. 不判断前10是否有hit，统一使用LLM重排序

**优点**:
- 🎯 结合向量检索和LLM语义理解
- 📊 结果质量通常较好
- 🔄 策略简单，易于理解

**缺点**:
- ⏱️ 速度较慢（所有查询都需要LLM重排序）
- 💰 成本较高（所有查询都消耗LLM token）
- 🔄 对于向量检索已经很好的情况，可能过度使用LLM

**适用场景**:
- 对精度要求高的场景
- 可以接受较高成本的场景
- 需要统一处理策略的情况

---

### 方案5: 向量+LLM（智能混合模式）(`vector_with_llm`) ⭐ **推荐**

**工作流程**:
1. 使用微调后的NER模型生成查询向量
2. 在ES中进行KNN向量检索（获取前10个结果）
3. **智能判断**：
   - 如果前10个结果中有正确链接（hit）：
     → 使用LLM对向量检索结果进行重排序
   - 如果前10个结果中没有正确链接（no hit）：
     → 直接从ES文本搜索获取候选，用LLM判断（不参考向量检索结果）

**优点**:
- 🎯 自适应策略，兼顾效率和精度
- 💰 成本可控（只在需要时使用LLM）
- 📊 结合多种检索方法的优势
- 🔄 对向量检索效果好和不好的情况都有应对

**缺点**:
- 🔧 实现相对复杂
- ⏱️ 需要判断前10是否有hit（但判断很快）

**适用场景**:
- **推荐用于生产环境**
- 需要平衡精度和成本的场景
- 查询质量差异较大的情况

---

## 📈 评估指标

所有方案都会计算以下指标：

- **MRR (Mean Reciprocal Rank)**: 平均倒数排名
- **Hit@1**: 正确结果排在第1位的比例
- **Hit@5**: 正确结果排在前5位的比例
- **Hit@10**: 正确结果排在前10位的比例

---

## 🚀 使用方法

### 评估所有方案

```bash
cd work_wyy
python search_vllm.py
```

默认会依次评估所有5种方案，并输出对比报告。

### 评估单个方案

```bash
# 方案1: 纯向量检索
python search_vllm.py --vector-only

# 方案2: 纯ES文本搜索
python search_vllm.py --es-text-only

# 方案3: 纯LLM判断
python search_vllm.py --llm-only

# 方案4: 向量+LLM（始终重排序）
python search_vllm.py --vector-llm-always

# 方案5: 向量+LLM（智能混合模式）
python search_vllm.py --vector-llm
```

### 查看评估报告

评估完成后会生成：
- **详细报告**: `evaluation_report_{模式}_{时间戳}.json`
- **汇总报告**: `evaluation_summary_{时间戳}.json`

---

## 📊 预期对比结果

根据理论分析，预期各方案的性能排序（从高到低）：

1. **方案5 (智能混合)**: 应该表现最好，自适应策略
2. **方案4 (向量+LLM始终)**: 应该表现很好，但成本较高
3. **方案3 (纯LLM)**: 语义理解强，但可能受ES文本搜索候选质量影响
4. **方案1 (纯向量)**: 速度快，但可能受向量质量限制
5. **方案2 (纯ES文本)**: 作为baseline，可能表现最差

**注意**: 实际结果可能因数据集、查询类型等因素有所不同。

---

## 💡 选择建议

- **生产环境推荐**: 方案5（智能混合模式）
- **快速测试**: 方案1（纯向量检索）
- **高精度要求**: 方案4（向量+LLM始终）
- **成本敏感**: 方案1或方案2
- **语义理解优先**: 方案3（纯LLM）

---

## 📝 技术细节

### 向量生成
- 使用微调后的NER模型（`./model/ner_finetuned`）
- 从`BertForTokenClassification`中提取`bert` encoder部分
- 向量维度：1024维，L2归一化

### ES检索
- 索引名称：`data2`
- 向量字段：7个（descriptions_zh_vector, descriptions_en_vector, high_freq_words_zh_vector, high_freq_words_en_vector, label_vector, label_zh_vector, label_en_vector）
- 文本搜索字段：label, aliases_zh, aliases_en, descriptions_zh, descriptions_en

### LLM配置
- 模型：`glm-4-flash`
- 用途：获取实体信息、判断语义匹配度

---

---

## 📝 更新日志

- **v1.0 (2025-12-08)**: 
  - 初始版本，支持5种检索方案对比
  - 方案1: 纯向量检索
  - 方案2: 纯ES文本搜索
  - 方案3: 纯LLM判断
  - 方案4: 向量+LLM（始终重排序）
  - 方案5: 向量+LLM（智能混合模式，推荐）

---

**文档版本**: v1.0  
**最后更新**: 2025-12-08  
**相关文件**: `search_vllm.py` - 检索系统主程序

