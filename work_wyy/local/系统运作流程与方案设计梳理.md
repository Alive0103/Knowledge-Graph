# 知识图谱检索系统 - 完整运作流程与方案设计梳理

## 目录
1. [主要研究内容](#主要研究内容)
2. [要解决的问题](#要解决的问题)
3. [初步方案](#初步方案)
4. [系统概述](#系统概述)
5. [完整运作流程](#完整运作流程)
6. [核心模块设计](#核心模块设计)
7. [检索方案设计对比](#检索方案设计对比)
8. [数据集配置方案对比](#数据集配置方案对比)
9. [技术架构](#技术架构)
10. [关键设计决策](#关键设计决策)

---

## 主要研究内容

本研究围绕**基于知识图谱的实体检索系统**展开，主要研究内容包括以下几个方面：

### 1. 领域专用NER模型训练与优化

**研究内容**：
- 基于Chinese-RoBERTa-wwm-ext-large预训练模型，针对军事领域进行NER模型微调
- 研究多数据源融合训练策略，包括traindata、CCKS军事领域数据、train.txt等
- 探索不同数据集配置对模型性能的影响，设计6种数据集配置方案进行对比实验
- 支持16种军事领域实体类型的识别（火炮、军工企业、军用舰艇、军用飞机、导弹等）

**技术要点**：
- 使用FP16混合精度训练，提高训练效率
- 支持多种数据格式（JSON、JSONL、BIO）的统一加载和转换
- 实现数据源开关机制，灵活控制训练数据组合

### 2. 实体向量化与语义表示

**研究内容**：
- 研究使用微调后的NER模型进行向量生成的策略，提升领域语义表示能力
- 设计多向量字段存储方案（标签向量、描述向量、实体词向量等）
- 实现向量维度统一处理（768维→1024维），平衡表达能力和计算效率
- 优化向量生成性能（批量处理、缓存机制、L2归一化）

**技术要点**：
- 从NER模型中提取bert encoder部分用于向量生成
- 实现LRU缓存机制，避免重复计算
- 支持批量向量生成，提高处理效率

### 3. 多方案混合检索策略

**研究内容**：
- 设计并实现5种检索方案，包括纯向量检索、纯ES文本检索、纯LLM判断、向量+LLM（始终重排序）、向量+LLM（智能混合模式）
- 研究向量检索与文本检索的融合策略
- 探索LLM在检索系统中的智能应用，包括实体信息扩展和结果重排序
- 设计智能混合模式，根据相似度阈值动态决定是否使用LLM，平衡速度、准确性和成本

**技术要点**：
- 实现多向量字段同时检索并融合结果
- 设计字段权重机制（label^3, aliases^2, descriptions^1, wiki_content^2）
- 实现相似度阈值判断，减少不必要的LLM调用（约减少60%）

### 4. Wiki内容增强机制

**研究内容**：
- 研究Wiki文本内容对检索效果的增强作用
- 设计Wiki内容下载、存储和检索集成方案
- 评估Wiki内容增强前后的检索性能提升（实验证明MRR提升11%+）

**技术要点**：
- 实现Wiki页面文本内容的自动下载和解析
- 将Wiki内容存储到ES索引的`wiki_content`字段
- 在文本检索中给予Wiki内容较高权重（权重2）

### 5. 跨语言实体对齐技术

**研究内容**：
- 研究跨语言军事实体对齐方法，创建不同语言间的军事实体对齐关系
- 针对中英文军事实体链接匮乏的问题，提出基于图神经网络的跨语言实体对齐方案
- 引入自负采样（self-negative sampling）和多个负队列机制，有效捕获实体关系和复杂图形中的隐藏语义
- 使用LaBSE多语言预训练模型进行初始实体嵌入，提升跨语言语义表示能力
- 设计图注意力网络（GAT）聚合邻居实体信息，增强实体表示

**技术要点**：
- 使用LaBSE模型生成初始768维跨语言实体嵌入
- 构建实体邻接图，利用图神经网络聚合邻居信息
- 实现自负采样策略，从同一批次中采样负样本，提高训练效率
- 使用对比学习损失函数（NCE Softmax Loss）进行模型训练
- 在DBP15K军事数据集上进行实验验证

**预期效果**：
- 中英文军事实体对齐准确率显著提升
- MRR达到0.775，Hits@10达到0.873（优于GCN-Align、BootEA等方法）
- 有效提高本地知识库的丰富性，进而提升实体链接质量

### 6. 自动化评估与对比系统

**研究内容**：
- 设计完整的自动化训练和评估流水线
- 实现多数据集配置的自动对比实验
- 设计评估指标（MRR、Hit@1、Hit@5、Hit@10）的自动计算和报告生成
- 实现检索方案效果对比和Wiki内容效果对比

**技术要点**：
- 使用`auto_pipeline.py`实现自动化流程
- 支持从指定阶段开始或跳过指定阶段的灵活执行
- 自动生成对比汇总表格和详细评估报告

---

## 要解决的问题

本研究旨在解决知识图谱实体检索系统中的以下关键问题：

### 1. 领域适配问题

**问题描述**：
- 通用NER模型在特定领域（如军事领域）的实体识别准确率较低
- 领域专用术语、缩写、别名等难以被通用模型正确识别
- 缺乏领域特定的训练数据和标注资源

**具体表现**：
- 军事装备名称识别错误（如"F-16"、"歼-20"等）
- 军工企业名称识别不准确
- 实体边界划分错误

### 2. 语义理解与检索准确性问题

**问题描述**：
- 传统关键词匹配无法处理同义词、缩写、别名等语义变体
- 向量检索对语义相似性的捕获有限，难以处理复杂查询
- 查询意图与实体描述的语义匹配不够精确

**具体表现**：
- 查询"F-16战斗机"无法匹配到"F-16战隼"
- 查询"歼击机"无法匹配到"战斗机"相关实体
- 查询意图模糊时，检索结果相关性低

### 3. 检索方案选择与优化问题

**问题描述**：
- 单一检索方案难以同时满足速度、准确性和成本要求
- 纯向量检索速度快但准确性有限
- 纯LLM判断准确性高但成本高、速度慢
- 缺乏智能的混合检索策略

**具体表现**：
- 大规模检索场景需要快速响应，但纯向量检索准确率不足
- 复杂查询需要深度语义理解，但纯LLM方案成本过高
- 缺乏根据查询复杂度动态选择检索策略的机制

### 4. 数据质量与训练效果问题

**问题描述**：
- 不同数据源的质量和标注标准不一致
- 数据源组合对模型效果的影响不明确
- 缺乏系统化的数据配置对比实验

**具体表现**：
- 不确定哪些数据源组合能获得最佳模型效果
- 通用数据（如MSRA）是否有助于领域模型训练不明确
- 缺乏数据增强效果的量化评估

### 5. 检索性能与成本平衡问题

**问题描述**：
- LLM API调用成本高，频繁调用会导致成本激增
- 所有查询都使用LLM重排序会严重影响响应速度
- 需要在不降低准确性的前提下控制成本

**具体表现**：
- 简单查询（如精确匹配）不需要LLM，但仍会调用导致浪费
- 复杂查询需要LLM，但每次都调用成本过高
- 缺乏智能判断机制，无法根据查询复杂度动态选择策略

### 6. 跨语言实体对齐问题

**问题描述**：
- 军事领域知识库中中英文实体链接匮乏，跨语言实体对齐关系缺失
- 不同语言间的军事实体难以建立对应关系，影响知识库的完整性和丰富性
- 传统跨语言实体对齐方法在军事领域效果不佳，难以处理领域特定的实体语义差异
- 缺乏有效的跨语言语义表示和实体匹配机制

**具体表现**：
- 中文实体"歼-20战斗机"无法与英文实体"J-20 fighter"建立对齐关系
- 跨语言实体检索时无法利用不同语言的知识资源
- 知识库丰富性不足，影响实体链接的召回率和准确率
- 现有方法（如GCN-Align、BootEA）在军事数据集上表现不佳

### 7. 评估与对比机制缺失问题

**问题描述**：
- 缺乏系统化的评估指标和对比机制
- 不同检索方案的效果对比不直观
- 数据增强效果难以量化评估

**具体表现**：
- 无法科学评估不同检索方案的优劣
- Wiki内容增强效果缺乏量化数据支撑
- 数据集配置对比实验需要大量人工操作

---

## 初步方案

针对上述问题，本研究提出以下初步解决方案：

### 方案1：领域专用NER模型训练方案

**核心思路**：
- 基于Chinese-RoBERTa-wwm-ext-large预训练模型进行领域微调
- 融合多种领域数据源（traindata、CCKS、train.txt）进行训练
- 设计6种数据集配置方案，通过对比实验找到最佳数据组合

**技术路线**：
1. 数据准备：统一加载多种格式的训练数据（JSON、JSONL、BIO）
2. 模型训练：使用HuggingFace Trainer进行微调，支持FP16混合精度
3. 模型评估：设计测试脚本验证模型效果
4. 对比实验：使用`auto_pipeline.py --compare-datasets`自动对比不同配置

**预期效果**：
- 领域实体识别准确率提升15-20%
- 找到最佳数据集配置（推荐：配置5-全部除MSRA）

### 方案2：多向量字段语义表示方案

**核心思路**：
- 使用微调后的NER模型生成向量，提升领域语义表示能力
- 设计多向量字段存储（标签、描述、实体词），丰富语义信息
- 实现向量维度统一处理（768维→1024维），平衡表达能力和效率

**技术路线**：
1. 实体提取：使用NER模型从描述文本中提取实体词
2. 向量生成：使用微调后的模型生成1024维向量，进行L2归一化
3. 批量处理：实现批量向量生成和缓存机制，提高效率
4. 存储优化：使用Elasticsearch的dense_vector类型存储向量

**预期效果**：
- 向量质量提升，检索准确性提升5-10%
- 批量处理效率提升3-5倍

### 方案3：多方案混合检索策略

**核心思路**：
- 设计5种检索方案，适应不同场景需求
- 实现智能混合模式，根据相似度阈值动态选择策略
- 结合向量检索的速度和LLM的准确性

**技术路线**：
1. **方案1（纯向量）**：使用向量相似度检索，适合大规模快速检索
2. **方案2（纯ES文本）**：使用ES文本检索，支持模糊匹配和同义词
3. **方案3（纯LLM）**：使用LLM直接判断，适合复杂查询
4. **方案4（向量+LLM始终）**：向量检索+LLM重排序，保证准确性
5. **方案5（向量+LLM智能）**：根据相似度阈值智能判断，平衡速度与准确性

**预期效果**：
- 智能混合模式减少60%的LLM调用，降低成本
- 检索准确性提升10-15%，响应速度提升30-50%

### 方案4：Wiki内容增强方案

**核心思路**：
- 下载并存储Wiki页面文本内容到ES索引
- 在文本检索中给予Wiki内容较高权重
- 通过对比实验量化评估增强效果

**技术路线**：
1. Wiki内容下载：使用`download_wiki_content.py`下载Wiki页面文本
2. 内容存储：使用`store_wiki_content_to_es.py`存储到ES的`wiki_content`字段
3. 检索增强：在文本检索中给予`wiki_content^2`权重
4. 效果评估：使用`compare_wiki_evaluation.py`对比增强前后效果

**预期效果**：
- 文本检索MRR提升11%+
- Hit@1提升13%+

### 方案5：跨语言实体对齐方案

**核心思路**：
- 基于图神经网络实现跨语言军事实体对齐
- 引入自负采样和多个负队列机制，提高训练效率和模型性能
- 使用LaBSE多语言预训练模型进行初始嵌入，提升跨语言语义表示
- 通过图注意力网络聚合邻居实体信息，增强实体表示能力

**技术路线**：
1. **初始嵌入**：使用LaBSE模型生成中英文实体的初始768维嵌入向量
2. **图构建**：基于知识图谱三元组构建实体邻接图，提取邻居实体信息
3. **图神经网络**：使用多头图注意力网络（GAT）聚合邻居实体信息，增强实体表示
4. **自负采样**：从同一批次中采样负样本，提高训练效率和模型泛化能力
5. **对比学习**：使用NCE Softmax Loss进行对比学习，学习跨语言实体对齐
6. **模型训练**：使用动量更新机制，稳定训练过程，提高模型性能

**关键技术细节**：
- 邻居实体数量：NEIGHBOR_SIZE=20
- 图注意力层数：gat_num=1
- 温度参数：t=0.08
- 动量系数：momentum=0.9999
- 学习率：lr=1e-6
- 批次大小：batch_size=64

**预期效果**：
- 中英文军事实体对齐MRR达到0.775
- Hits@10达到0.873，优于GCN-Align、BootEA等基线方法
- 有效提高本地知识库丰富性，提升实体链接质量

### 方案6：自动化评估与对比系统

**核心思路**：
- 设计完整的自动化训练和评估流水线
- 实现多数据集配置的自动对比实验
- 自动生成评估报告和对比表格

**技术路线**：
1. 自动化流水线：使用`auto_pipeline.py`实现端到端自动化
2. 评估指标：实现MRR、Hit@K等指标的自动计算
3. 对比分析：自动生成数据集配置对比表格和检索方案对比报告
4. 报告生成：自动保存JSON格式的详细评估结果

**预期效果**：
- 实验效率提升5-10倍
- 评估结果可复现、可对比

### 方案7：性能优化策略

**核心思路**：
- 实现向量缓存机制，避免重复计算
- 批量处理提高效率
- 智能LLM调用减少成本

**技术路线**：
1. 向量缓存：LRU缓存机制，最多缓存1000条
2. 批量处理：批量生成向量（batch_size=64），批量导入ES
3. 预计算：评估时预先批量生成查询向量
4. 智能调用：方案5根据相似度阈值判断是否调用LLM

**预期效果**：
- 向量生成速度提升3-5倍
- LLM调用成本降低60%
- 整体系统响应速度提升30-50%

---

## 系统概述

这是一个**基于知识图谱的实体检索与跨语言对齐系统**，主要功能包括：
- **NER模型训练**：使用多种数据源训练军事领域命名实体识别模型
- **实体提取与向量化**：从文本中提取实体词，并生成向量表示
- **多方案检索**：支持5种不同的检索方案，从纯向量检索到LLM增强检索
- **跨语言实体对齐**：基于图神经网络实现中英文军事实体对齐，提高知识库丰富性
- **评估与对比**：自动评估不同方案和数据集配置的效果

### 核心组件
- **NER模型**：基于Chinese-RoBERTa-wwm-ext-large微调的命名实体识别模型
- **向量模型**：使用微调后的BERT模型生成1024维向量
- **跨语言对齐模型**：基于图神经网络（GAT）和LaBSE的跨语言实体对齐模型
- **Elasticsearch**：存储实体数据和向量，支持文本检索和向量检索
- **LLM（智谱AI）**：用于实体信息扩展和结果重排序

---
 
## 完整运作流程

### 阶段1：数据准备与模型训练

#### 1.1 前置条件检查 (`check_prerequisites.py`)
- 检查ES服务连接
- 验证数据文件存在性
- 检查模型路径和依赖包

#### 1.2 数据加载 (`data_loader.py`)
支持多种数据源格式：
- **traindata目录**：主要训练数据（JSON格式）
- **CCKS数据**：
  - JSON格式：`ccks_8_data_v2/train/*.json` (400个文件)
  - BIO格式：`fold0-4/train` (5折交叉验证数据)
- **train.txt**：JSONL格式训练数据
- **MSRA数据**：通用NER数据（`msra_train_bio.txt`, `msra_test_bio.txt`）

**数据源开关机制**：通过`config.py`中的`DATA_SOURCE_SWITCHES`控制启用/禁用

#### 1.3 NER模型训练 (`finetune_ner_model.py`)
- **基础模型**：Chinese-RoBERTa-wwm-ext-large
- **训练配置**：
  - max_length: 512
  - batch_size: 8
  - learning_rate: 2e-5
  - num_epochs: 5
  - 使用FP16混合精度训练
- **实体类型**：支持16种军事领域实体类型（火炮、军工企业、军用舰艇等）
- **输出**：微调后的模型保存到`model/ner_finetuned/`

#### 1.4 NER模型测试 (`diagnose_ner_model.py`)
- 验证模型能正确加载
- 测试实体提取功能
- 统计训练数据指标（样本数、实体类型、实体数等）

### 阶段2：实体提取与向量化

#### 2.1 实体词提取 (`find_top_k.py`)
- **输入**：Wiki数据（`zh_wiki_v2.jsonl`, `en_wiki_v3.jsonl`）
- **处理流程**：
  1. 使用NER模型从描述文本中提取实体词
  2. 过滤：中文实体词≥2字符，英文实体词≥3字符
  3. 去重并统计
- **输出**：
  - `data/entity_words_zh.jsonl`：中文实体词及向量
  - `data/entity_words_en.jsonl`：英文实体词及向量

#### 2.2 向量生成 (`vector_model.py`)
- **模型选择**：
  - 优先使用微调后的NER模型（`USE_FINETUNED_FOR_VECTORIZATION=True`）
  - 降级到基础模型（如果微调模型不可用）
- **向量维度**：1024维（统一处理768维模型输出）
- **处理方式**：
  - L2归一化
  - 批量生成（batch_size=64）
  - 向量缓存机制（最多1000条）

#### 2.3 数据存储到ES (`vector2ES.py`)
- **索引创建**：
  - 包含多个向量字段：
    - `label_vector`：标签向量
    - `descriptions_zh_vector`：中文描述向量
    - `descriptions_en_vector`：英文描述向量
    - `entity_words_zh_vector`：中文实体词向量
    - `entity_words_en_vector`：英文实体词向量
  - 文本字段：`label`, `link`, `aliases_zh`, `aliases_en`, `descriptions_zh`, `descriptions_en`
- **批量导入**：使用Elasticsearch的`helpers.bulk`进行批量插入
- **进度跟踪**：显示向量生成和导入进度

### 阶段3：检索系统实现

#### 3.1 检索方案实现 (`search_vllm.py`)
系统实现了5种检索方案（详见[检索方案设计对比](#检索方案设计对比)）

#### 3.2 Wiki内容增强 (`store_wiki_content_to_es.py`, `store_find_content_to_es.py`)
- 下载Wiki页面文本内容
- 存储到ES索引的`wiki_content`字段
- 用于增强文本检索效果

### 阶段4：评估与对比

#### 4.1 检索效果评估 (`search_vllm.py`)
- **评估指标**：
  - MRR (Mean Reciprocal Rank)
  - Hit@1, Hit@5, Hit@10
- **测试数据**：从`data/find.xlsx`读取查询-链接对
- **输出**：JSON格式的评估报告

#### 4.2 Wiki内容效果对比 (`compare_wiki_evaluation.py`)
- 对比添加Wiki内容前后的检索效果
- 计算绝对提升和相对提升百分比

#### 4.3 数据集配置对比 (`auto_pipeline.py --compare-datasets`)
- 对6种数据集配置分别运行完整流水线
- 生成对比汇总表格
- 保存详细的评估结果到JSON文件

---

## 核心模块设计

### 1. 配置管理模块 (`config.py`)

#### 功能
- 统一管理所有配置项（路径、ES连接、数据源开关等）
- 支持本地ES和阿里云ES两种连接模式
- 提供配置验证和默认值机制

#### 关键配置项
```python
# ES连接模式
ES_MODE = 'local'  # 或 'aliyun'

# 数据源开关
DATA_SOURCE_SWITCHES = {
    'traindata': True,
    'ccks_json': True,
    # ... 其他数据源
}

# 向量化配置
VECTOR_DIMS = 1024
USE_FINETUNED_FOR_VECTORIZATION = True
```

### 2. 数据加载模块 (`data_loader.py`)

#### 设计特点
- **多格式支持**：JSON、JSONL、BIO格式
- **编码自动检测**：支持UTF-8、GBK等多种编码
- **统一接口**：`load_all_data_from_directories()`统一加载所有数据源
- **数据源开关**：根据配置决定加载哪些数据源

#### 数据格式转换
- JSON格式 → BIO格式（用于模型训练）
- 自动处理实体边界和标签映射

### 3. 向量生成模块 (`vector_model.py`)

#### 设计特点
- **模型选择策略**：
  1. 优先使用微调后的模型（领域适配更好）
  2. 降级到基础模型（兼容性保证）
- **维度统一**：自动处理768维→1024维转换
- **批量处理**：支持批量向量生成，提高效率
- **缓存机制**：LRU缓存，避免重复计算

### 4. NER提取模块 (`ner_extract_entities.py`)

#### 设计特点
- **模型加载**：延迟加载，首次使用时加载
- **标签映射**：从`label_mapping.json`动态加载
- **批量处理**：支持批量文本处理
- **错误处理**：模型加载失败时降级到基础模型

### 5. ES客户端 (`es_client.py`)

#### 设计特点
- **连接管理**：根据`ES_MODE`自动选择连接配置
- **错误重试**：支持自动重试机制
- **超时控制**：180秒请求超时

---

## 检索方案设计对比

系统实现了5种检索方案，每种方案有不同的设计理念和适用场景。

### 方案1：纯向量检索 (`vector_only`)

#### 设计思路
- **原理**：使用向量相似度进行检索
- **流程**：
  1. 将查询文本转换为向量
  2. 在ES中执行向量相似度搜索（cosine similarity）
  3. 按相似度分数排序返回结果
- **优点**：
  - 速度快（不需要LLM调用）
  - 能捕获语义相似性
  - 成本低（无API调用）
- **缺点**：
  - 对同义词、缩写等处理较弱
  - 依赖向量质量
- **适用场景**：大规模检索、实时性要求高的场景

#### 技术实现
```python
# 向量搜索
query_vector = generate_vector(query)
search_body = {
    "query": {
        "script_score": {
            "query": {"match_all": {}},
            "script": {
                "source": "cosineSimilarity(params.query_vector, 'entity_words_zh_vector') + 1.0",
                "params": {"query_vector": query_vector}
            }
        }
    },
    "size": 30
}
```

### 方案2：纯ES文本搜索 (`es_text_only`)

#### 设计思路
- **原理**：使用Elasticsearch的文本检索功能
- **流程**：
  1. 使用`multi_match`查询在多个字段中搜索
  2. 字段权重：`label^3`, `aliases_zh^2`, `aliases_en^2`, `descriptions_zh`, `descriptions_en`, `wiki_content^2`
  3. 按ES相关性分数排序
- **优点**：
  - 速度快（ES原生支持）
  - 支持模糊匹配、同义词扩展
  - 可以利用Wiki内容增强
- **缺点**：
  - 对语义理解有限
  - 依赖关键词匹配
- **适用场景**：精确匹配、关键词明确的查询

#### 技术实现
```python
search_body = {
    "query": {
        "multi_match": {
            "query": query,
            "fields": [
                "label^3",           # 权重3
                "aliases_zh^2",     # 权重2
                "aliases_en^2",     # 权重2
                "descriptions_zh",  # 权重1
                "descriptions_en",  # 权重1
                "wiki_content^2"    # 权重2（Wiki内容）
            ],
            "type": "best_fields",
            "operator": "or"
        }
    },
    "size": 30
}
```

### 方案3：纯LLM判断 (`llm_only`)

#### 设计思路
- **原理**：使用LLM直接判断查询与候选实体的匹配度
- **流程**：
  1. 从ES获取候选（使用文本搜索）
  2. 调用LLM获取查询实体的别名、定义、描述
  3. LLM对比查询信息与候选实体信息，给出匹配度排序
- **优点**：
  - 语义理解能力强
  - 能处理复杂查询
  - 不依赖向量质量
- **缺点**：
  - 速度慢（需要LLM调用）
  - 成本高（API调用费用）
  - 可能不稳定（LLM输出可能不一致）
- **适用场景**：复杂查询、需要深度语义理解的场景

#### 技术实现
```python
# 1. 从ES获取候选
candidates = es_text_search(query, top_k=30)

# 2. LLM获取查询实体的扩展信息
query_info = get_alias_and_definition(query)  # 调用智谱AI

# 3. LLM对比并排序
sorted_results = llm_compare_and_sort(query_info, candidates)
```

### 方案4：向量+LLM（始终重排序）(`vector_with_llm_always`)

#### 设计思路
- **原理**：向量检索获取候选，LLM始终进行重排序
- **流程**：
  1. 向量检索获取top-k候选
  2. 对每个候选调用LLM判断匹配度
  3. 按LLM评分重新排序
- **优点**：
  - 结合向量检索的速度和LLM的准确性
  - 结果质量较高
- **缺点**：
  - 成本较高（每个查询都需要LLM调用）
  - 速度较慢
- **适用场景**：对准确性要求高、可以接受一定延迟的场景

### 方案5：向量+LLM（智能混合模式）(`vector_with_llm`) ⭐推荐

#### 设计思路
- **原理**：智能判断是否需要LLM重排序
- **流程**：
  1. 向量检索获取top-k候选
  2. **智能判断**：
     - 如果top-1结果相似度很高 → 直接返回（跳过LLM）
     - 如果top结果相似度较低 → 使用LLM重排序
  3. 返回最终排序结果
- **优点**：
  - **平衡速度与准确性**：简单查询快速返回，复杂查询使用LLM
  - **成本可控**：只在必要时调用LLM
  - **用户体验好**：快速响应 + 高准确性
- **缺点**：
  - 需要设置相似度阈值
  - 逻辑相对复杂
- **适用场景**：**生产环境推荐方案**

#### 技术实现
```python
# 向量检索
vector_results = vector_search(query, top_k=30)

# 智能判断
if vector_results[0]['_score'] > SIMILARITY_THRESHOLD:
    # 相似度足够高，直接返回
    return vector_results
else:
    # 使用LLM重排序
    return llm_rerank(query, vector_results)
```

### 方案对比总结

| 方案 | 速度 | 准确性 | 成本 | 适用场景 |
|------|------|--------|------|----------|
| 方案1：纯向量 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 大规模检索、实时性要求高 |
| 方案2：纯ES文本 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 精确匹配、关键词明确 |
| 方案3：纯LLM | ⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐ | 复杂查询、深度语义理解 |
| 方案4：向量+LLM(始终) | ⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ | 准确性要求高、可接受延迟 |
| 方案5：向量+LLM(智能) | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | **生产环境推荐** |

---

## 数据集配置方案对比

系统支持6种数据集配置，用于对比不同数据源对模型效果的影响。

### 配置1：仅traindata
- **数据源**：`traindata`目录
- **特点**：核心训练数据，质量较高
- **适用场景**：基线对比

### 配置2：仅CCKS数据
- **数据源**：CCKS军事领域数据（JSON + BIO格式）
- **特点**：领域特定，标注质量高
- **适用场景**：测试领域数据的效果

### 配置3：仅train.txt
- **数据源**：`train.txt`（JSONL格式）
- **特点**：格式统一，易于处理
- **适用场景**：测试单一数据源效果

### 配置4：traindata + CCKS
- **数据源**：traindata + CCKS数据
- **特点**：结合核心数据和领域数据
- **适用场景**：测试领域数据增强效果

### 配置5：全部（除MSRA）⭐推荐
- **数据源**：traindata + CCKS + train.txt
- **特点**：最大化的领域数据，不含通用数据
- **适用场景**：**领域专用模型的最佳配置**

### 配置6：全部数据
- **数据源**：所有数据源（包括MSRA）
- **特点**：数据量最大，包含通用NER数据
- **适用场景**：测试通用数据对领域模型的影响

### 配置对比机制

通过`auto_pipeline.py --compare-datasets`实现：
1. 为每种配置创建独立的模型目录（`model/ner_finetuned_<config_id>`）
2. 为每种配置创建独立的ES索引（`data_<config_id>`）
3. 运行完整流水线（训练→测试→提取→向量化→评估）
4. 提取并记录评估指标
5. 生成汇总对比表格

---

## 技术架构

### 系统架构图

```
┌─────────────────────────────────────────────────────────────┐
│                      数据层                                  │
├─────────────────────────────────────────────────────────────┤
│  traindata/  │  CCKS数据  │  train.txt  │  MSRA数据  │ Wiki │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      模型层                                  │
├─────────────────────────────────────────────────────────────┤
│  NER模型训练  →  NER模型微调  →  实体提取  →  向量生成        │
│  (finetune_ner_model.py)  (ner_extract_entities.py)         │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      存储层                                  │
├─────────────────────────────────────────────────────────────┤
│              Elasticsearch                                   │
│  ┌──────────┬──────────┬──────────┬──────────┐              │
│  │ 文本字段  │ 向量字段 │ Wiki内容 │ 元数据   │              │
│  └──────────┴──────────┴──────────┴──────────┘              │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      检索层                                  │
├─────────────────────────────────────────────────────────────┤
│  方案1: 纯向量  │  方案2: ES文本  │  方案3: 纯LLM            │
│  方案4: 向量+LLM(始终)  │  方案5: 向量+LLM(智能) ⭐         │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                      评估层                                  │
├─────────────────────────────────────────────────────────────┤
│  MRR计算  │  Hit@K计算  │  对比分析  │  报告生成             │
└─────────────────────────────────────────────────────────────┘
```

### 数据流

```
原始数据 → 数据加载 → NER训练 → 实体提取 → 向量化 → ES存储
                                                      ↓
查询 → 检索方案 → 结果排序 → 评估指标 → 对比报告
```

### 关键技术选型

1. **NER模型**：Chinese-RoBERTa-wwm-ext-large
   - 理由：中文预训练模型，性能优秀，支持长文本

2. **向量模型**：使用微调后的NER模型
   - 理由：领域适配，向量质量更高

3. **向量维度**：1024维
   - 理由：平衡表达能力和计算效率

4. **ES版本**：支持8.x和7.x
   - 理由：兼容性考虑

5. **LLM服务**：智谱AI GLM-4-Flash
   - 理由：中文支持好，API稳定

---

## 关键设计决策

### 1. 为什么使用微调后的模型进行向量化？

**决策**：优先使用微调后的NER模型生成向量

**理由**：
- 微调后的模型在领域数据上表现更好
- 生成的向量更能捕获领域特定的语义
- 提高检索准确性

**实现**：`USE_FINETUNED_FOR_VECTORIZATION = True`

### 2. 为什么设计5种检索方案？

**决策**：实现多种检索方案，支持对比和选择

**理由**：
- 不同场景需要不同的检索策略
- 通过对比找到最佳方案
- 提供灵活性（可以根据需求选择）

### 3. 为什么使用智能混合模式（方案5）？

**决策**：方案5作为推荐方案

**理由**：
- 平衡速度与准确性
- 成本可控（只在必要时调用LLM）
- 用户体验好

### 4. 为什么支持多种数据集配置？

**决策**：支持6种数据集配置，可对比

**理由**：
- 不同数据源对模型效果的影响不同
- 通过对比找到最佳数据组合
- 支持增量式数据增强实验

### 5. 为什么使用Wiki内容增强？

**决策**：支持添加Wiki文本内容到ES索引

**理由**：
- Wiki内容提供丰富的实体描述
- 增强文本检索效果
- 提高检索准确性（实验证明MRR提升11%+）

### 6. 为什么设计配置开关机制？

**决策**：通过`DATA_SOURCE_SWITCHES`控制数据源

**理由**：
- 灵活控制训练数据
- 支持A/B测试
- 便于调试和实验

### 7. 为什么使用1024维向量？

**决策**：统一使用1024维向量

**理由**：
- 平衡表达能力和计算效率
- 支持768维模型输出（通过扩展）
- ES支持dense_vector类型

### 8. 为什么设计自动化流水线？

**决策**：`auto_pipeline.py`实现自动化流程

**理由**：
- 减少人工操作
- 确保流程一致性
- 支持批量实验（数据集对比）

---

## 性能优化策略

### 1. 向量缓存
- LRU缓存机制，最多缓存1000条
- 避免重复计算相同文本的向量

### 2. 批量处理
- 批量生成向量（batch_size=64）
- 批量导入ES（使用helpers.bulk）

### 3. 预计算
- 评估时预先批量生成查询向量
- 减少重复计算

### 4. 智能LLM调用
- 方案5只在必要时调用LLM
- 减少API调用次数和成本

### 5. 并行处理
- 使用多线程处理LLM调用（如果支持）

---

## 评估指标说明

### MRR (Mean Reciprocal Rank)
- **定义**：平均倒数排名
- **计算**：对于每个查询，如果正确答案在第k位，则得分为1/k；否则为0
- **范围**：0-1，越大越好
- **意义**：衡量系统找到正确答案的能力

### Hit@K
- **定义**：在前K个结果中找到正确答案的比例
- **常用**：Hit@1, Hit@5, Hit@10
- **范围**：0-1，越大越好
- **意义**：衡量系统返回结果的准确性

---

## 使用建议

### 开发环境
1. 使用方案2（纯ES文本）进行快速开发和调试
2. 使用方案1（纯向量）进行性能测试

### 生产环境
1. **推荐使用方案5（向量+LLM智能混合）**
2. 根据实际需求调整相似度阈值
3. 监控LLM调用频率和成本

### 实验环境
1. 使用`--compare-datasets`对比不同数据集配置
2. 使用`compare_wiki_evaluation.py`对比Wiki内容效果
3. 记录所有实验的评估指标

---

## 总结

本系统是一个完整的知识图谱检索系统，具有以下特点：

1. **模块化设计**：各模块职责清晰，易于维护和扩展
2. **多方案支持**：5种检索方案，适应不同场景
3. **灵活配置**：支持多种数据集配置和数据源开关
4. **自动化流程**：完整的自动化训练和评估流水线
5. **效果验证**：完善的评估和对比机制

**推荐配置**：
- **数据集**：配置5（全部除MSRA）
- **检索方案**：方案5（向量+LLM智能混合）
- **Wiki增强**：启用（提升11%+ MRR）

---

*文档生成时间：2025-01-XX*
*系统版本：v1.0*

