#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NERæ¨¡å‹è¯Šæ–­è„šæœ¬
ç”¨äºåˆ†æå¾®è°ƒåçš„NERæ¨¡å‹æ•ˆæœï¼Œæä¾›ç§‘å­¦çš„è¯Šæ–­å’Œæ”¹è¿›å»ºè®®
"""

import torch
from transformers import BertTokenizer, BertForTokenClassification
import os
import json
import logging
from collections import Counter
import glob

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ¨¡å‹è·¯å¾„ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ŒåŸºäºè„šæœ¬ä½ç½®ï¼‰
_script_dir = os.path.dirname(os.path.abspath(__file__))
_parent_dir = os.path.dirname(_script_dir)  # work_wyy ç›®å½•

# ä¼˜å…ˆä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹
NER_MODEL_PATH = os.path.join(_parent_dir, 'model', 'ner_finetuned')
BASE_MODEL_PATH = os.path.join(_parent_dir, 'model', 'chinese-roberta-wwm-ext-large')

MAX_LENGTH = 512

# é»˜è®¤æ ‡ç­¾æ˜ å°„ï¼ˆå¦‚æœæ— æ³•åŠ è½½label_mapping.jsonåˆ™ä½¿ç”¨ï¼‰
LABEL_TO_ID = {'O': 0, 'B-ENTITY': 1, 'I-ENTITY': 2}
ID_TO_LABEL = {0: 'O', 1: 'B-ENTITY', 2: 'I-ENTITY'}


def load_label_mapping(model_path):
    """ä»label_mapping.jsonåŠ è½½æ ‡ç­¾æ˜ å°„"""
    global LABEL_TO_ID, ID_TO_LABEL
    
    label_mapping_file = os.path.join(model_path, 'label_mapping.json')
    if os.path.exists(label_mapping_file):
        try:
            with open(label_mapping_file, 'r', encoding='utf-8') as f:
                label_info = json.load(f)
                LABEL_TO_ID = label_info.get('label_to_id', LABEL_TO_ID)
                # ç¡®ä¿ID_TO_LABELçš„é”®æ˜¯æ•´æ•°ï¼ˆJSONä¸­çš„é”®å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰
                id_to_label_raw = label_info.get('id_to_label', {})
                ID_TO_LABEL = {int(k): v for k, v in id_to_label_raw.items()}
                logger.info(f"âœ… æˆåŠŸåŠ è½½æ ‡ç­¾æ˜ å°„: {len(LABEL_TO_ID)} ä¸ªæ ‡ç­¾")
                
                # ç»Ÿè®¡å®ä½“ç±»å‹
                entity_types = set()
                for label in LABEL_TO_ID.keys():
                    if label.startswith('B-'):
                        entity_types.add(label[2:])
                
                if entity_types:
                    logger.info(f"   æ”¯æŒçš„å®ä½“ç±»å‹: {len(entity_types)} ç§")
                    logger.info(f"   ç±»å‹åˆ—è¡¨: {', '.join(sorted(entity_types)[:10])}{'...' if len(entity_types) > 10 else ''}")
                
                return True
        except Exception as e:
            logger.warning(f"âš ï¸  åŠ è½½æ ‡ç­¾æ˜ å°„å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
            return False
    else:
        logger.warning(f"âš ï¸  æ ‡ç­¾æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {label_mapping_file}ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
        return False


def load_model():
    """åŠ è½½æ¨¡å‹"""
    global LABEL_TO_ID, ID_TO_LABEL
    
    # æ£€æŸ¥å¾®è°ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(NER_MODEL_PATH):
        logger.error(f"âŒ å¾®è°ƒæ¨¡å‹ä¸å­˜åœ¨: {NER_MODEL_PATH}")
        logger.error(f"   è¯·ç¡®ä¿æ¨¡å‹ä½äº: {NER_MODEL_PATH}")
        logger.error(f"   è¯·å…ˆè¿è¡Œ finetune_ner_model.py è®­ç»ƒæ¨¡å‹")
        return None, None, None
    
    logger.info(f"âœ… åŠ è½½æ¨¡å‹: {NER_MODEL_PATH}")
    
    # å…ˆåŠ è½½æ ‡ç­¾æ˜ å°„
    if not load_label_mapping(NER_MODEL_PATH):
        logger.warning("âš ï¸  æ ‡ç­¾æ˜ å°„åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„")
    
    try:
        tokenizer = BertTokenizer.from_pretrained(NER_MODEL_PATH)
        model = BertForTokenClassification.from_pretrained(NER_MODEL_PATH)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()
        
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {device}")
        return model, tokenizer, device
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None, None, None


def analyze_training_data():
    """åˆ†æè®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨data_loaderç»Ÿè®¡æ‰€æœ‰æ•°æ®æºï¼‰"""
    logger.info("=" * 70)
    logger.info("åˆ†æè®­ç»ƒæ•°æ®")
    logger.info("=" * 70)
    
    try:
        # å¯¼å…¥æ•°æ®åŠ è½½æ¨¡å—
        import sys
        sys.path.insert(0, _script_dir)
        from data_loader import load_all_data_from_directories
        
        # åŠ è½½æ‰€æœ‰æ•°æ®
        base_dir = os.path.join(_parent_dir, 'data')
        train_examples, dev_examples, all_entity_types = load_all_data_from_directories(base_dir)
        
        # ç»Ÿè®¡è®­ç»ƒæ•°æ®
        total_train_samples = len(train_examples)
        total_dev_samples = len(dev_examples)
        
        # ç»Ÿè®¡å®ä½“ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼šåªç»Ÿè®¡B-æ ‡ç­¾æ•°é‡ï¼‰
        total_entities = 0
        entity_types_counter = Counter()
        
        for example in train_examples:
            labels = example.get('labels', [])
            
            # ç»Ÿè®¡B-æ ‡ç­¾ï¼ˆå®ä½“å¼€å§‹ï¼‰
            for label in labels:
                if label.startswith('B-'):
                    total_entities += 1
                    entity_type = label[2:]
                    if entity_type:
                        entity_types_counter[entity_type] += 1
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"è®­ç»ƒæ ·æœ¬æ•°: {total_train_samples:,} æ¡")
        logger.info(f"éªŒè¯æ ·æœ¬æ•°: {total_dev_samples:,} æ¡")
        logger.info(f"æ€»å®ä½“æ•°: {total_entities:,} ä¸ª")
        if total_train_samples > 0:
            logger.info(f"å¹³å‡æ¯ä¸ªæ ·æœ¬çš„å®ä½“æ•°: {total_entities / total_train_samples:.2f}")
        logger.info(f"å®ä½“ç±»å‹æ€»æ•°: {len(all_entity_types)} ç§")
        
        if entity_types_counter:
            logger.info(f"\nå®ä½“ç±»å‹åˆ†å¸ƒï¼ˆTop 10ï¼‰:")
            for entity_type, count in entity_types_counter.most_common(10):
                logger.info(f"  {entity_type}: {count:,} ä¸ª")
        
        return {
            'train_samples': total_train_samples,
            'dev_samples': total_dev_samples,
            'total_entities': total_entities,
            'entity_types': len(all_entity_types),
            'avg_entities_per_sample': total_entities / total_train_samples if total_train_samples > 0 else 0
        }
        
    except Exception as e:
        logger.warning(f"âš ï¸  æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return None


def analyze_training_log():
    """åˆ†æè®­ç»ƒæ—¥å¿—ï¼Œæå–è®­ç»ƒä¿¡æ¯"""
    log_file = os.path.join(_script_dir, 'ner_finetune.log')
    
    if not os.path.exists(log_file):
        logger.warning(f"âš ï¸  è®­ç»ƒæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return None
    
    try:
        training_info = {
            'epochs': 0,
            'final_f1': None,
            'final_accuracy': None,
            'training_time': None
        }
        
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        # æŸ¥æ‰¾æœ€åçš„è¯„ä¼°ç»“æœå’Œè®­ç»ƒä¿¡æ¯
        for line in reversed(lines):
            # å°è¯•è§£æå­—å…¸æ ¼å¼çš„æ—¥å¿—ï¼ˆå¦‚ {'eval_f1': 0.98, ...}ï¼‰
            if '{' in line and ('eval_f1' in line or 'train_runtime' in line):
                try:
                    # æå–å­—å…¸éƒ¨åˆ†
                    dict_start = line.find('{')
                    dict_end = line.rfind('}') + 1
                    if dict_start >= 0 and dict_end > dict_start:
                        dict_str = line[dict_start:dict_end]
                        # å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·ï¼ˆPythonå­—å…¸æ ¼å¼è½¬JSONï¼‰
                        dict_str = dict_str.replace("'", '"')
                        log_data = json.loads(dict_str)
                        
                        # æå–è¯„ä¼°æŒ‡æ ‡ï¼ˆå–æœ€åä¸€ä¸ªepochçš„ç»“æœï¼‰
                        if 'eval_f1' in log_data:
                            f1_value = log_data.get('eval_f1', 0)
                            if training_info['final_f1'] is None or f1_value > training_info['final_f1']:
                                training_info['final_f1'] = f1_value
                        if 'eval_accuracy' in log_data:
                            acc_value = log_data.get('eval_accuracy', 0)
                            if training_info['final_accuracy'] is None or acc_value > training_info['final_accuracy']:
                                training_info['final_accuracy'] = acc_value
                        if 'epoch' in log_data:
                            epoch_value = float(log_data.get('epoch', 0))
                            training_info['epochs'] = max(training_info['epochs'], int(epoch_value))
                        if 'train_runtime' in log_data:
                            training_info['training_time'] = log_data.get('train_runtime', 0)
                except Exception as e:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨evalï¼ˆä¸å®‰å…¨ï¼Œä½†ä½œä¸ºå¤‡é€‰ï¼‰
                    try:
                        dict_start = line.find('{')
                        dict_end = line.rfind('}') + 1
                        if dict_start >= 0 and dict_end > dict_start:
                            dict_str = line[dict_start:dict_end]
                            log_data = eval(dict_str)  # ä½¿ç”¨evalè§£æPythonå­—å…¸æ ¼å¼
                            
                            if 'eval_f1' in log_data:
                                f1_value = log_data.get('eval_f1', 0)
                                if training_info['final_f1'] is None or f1_value > training_info['final_f1']:
                                    training_info['final_f1'] = f1_value
                            if 'eval_accuracy' in log_data:
                                acc_value = log_data.get('eval_accuracy', 0)
                                if training_info['final_accuracy'] is None or acc_value > training_info['final_accuracy']:
                                    training_info['final_accuracy'] = acc_value
                            if 'epoch' in log_data:
                                epoch_value = float(log_data.get('epoch', 0))
                                training_info['epochs'] = max(training_info['epochs'], int(epoch_value))
                            if 'train_runtime' in log_data:
                                training_info['training_time'] = log_data.get('train_runtime', 0)
                    except:
                        pass
        
        return training_info if training_info['epochs'] > 0 else None
        
    except Exception as e:
        logger.warning(f"âš ï¸  åˆ†æè®­ç»ƒæ—¥å¿—å¤±è´¥: {e}")
        return None


def test_prediction_detailed(text, model, tokenizer, device):
    """è¯¦ç»†æµ‹è¯•æ¨¡å‹é¢„æµ‹"""
    logger.info("\n" + "=" * 70)
    logger.info(f"æµ‹è¯•æ–‡æœ¬: {text}")
    logger.info("=" * 70)
    
    encoding = tokenizer(
        text,
        truncation=True,
        padding='max_length',
        max_length=MAX_LENGTH,
        return_tensors='pt'
    )
    
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)
        probabilities = torch.softmax(logits, dim=-1)
    
    input_ids_list = input_ids[0].cpu().tolist()
    predictions_list = predictions[0].cpu().tolist()
    tokens = tokenizer.convert_ids_to_tokens(input_ids_list)
    
    logger.info("\nTokençº§åˆ«çš„é¢„æµ‹ç»“æœï¼ˆå‰50ä¸ªtokenï¼‰:")
    logger.info("-" * 70)
    logger.info(f"{'Token':<30} {'Label':<15} {'Prob(O)':<10} {'Prob(B)':<10} {'Prob(I)':<10}")
    logger.info("-" * 70)
    
    for i, (token, pred_id) in enumerate(zip(tokens[:50], predictions_list[:50])):
        if token in ['[PAD]']:
            break
        label = ID_TO_LABEL.get(int(pred_id), 'O')
        probs = probabilities[0][i].cpu().tolist()
        
        # è®¡ç®—æ‰€æœ‰B-å’ŒI-æ ‡ç­¾çš„æ¦‚ç‡
        prob_o = probs[0] if 0 < len(probs) else 0.0
        
        # è®¡ç®—æ‰€æœ‰B-æ ‡ç­¾çš„æ¦‚ç‡æ€»å’Œ
        prob_b = 0.0
        prob_i = 0.0
        for label_id, label_name in ID_TO_LABEL.items():
            if label_id < len(probs):
                if label_name.startswith('B-'):
                    prob_b += probs[label_id]
                elif label_name.startswith('I-'):
                    prob_i += probs[label_id]
        
        logger.info(f"{token:<30} {label:<15} {prob_o:<10.4f} {prob_b:<10.4f} {prob_i:<10.4f}")
    
    # æå–å®ä½“ï¼ˆæ”¯æŒå¤šç§å®ä½“ç±»å‹ï¼‰
    entities = []
    current_entity_tokens = []
    current_entity_type = None
    
    for i, (token, pred_id) in enumerate(zip(tokens, predictions_list)):
        pred_id = int(pred_id)
        label = ID_TO_LABEL.get(pred_id, 'O')
        
        if token in ['[CLS]', '[SEP]', '[PAD]']:
            if current_entity_tokens:
                entity_text = ''.join(current_entity_tokens).replace('##', '')
                if entity_text and len(entity_text) >= 2:
                    entities.append(entity_text)
                current_entity_tokens = []
                current_entity_type = None
            continue
        
        clean_token = token.replace('##', '')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯B-æ ‡ç­¾ï¼ˆä»»ä½•å®ä½“ç±»å‹çš„å¼€å§‹ï¼‰
        if label.startswith('B-'):
            # ä¿å­˜ä¹‹å‰çš„å®ä½“
            if current_entity_tokens:
                entity_text = ''.join(current_entity_tokens).replace('##', '')
                if entity_text and len(entity_text) >= 2:
                    entities.append(entity_text)
            # å¼€å§‹æ–°å®ä½“
            current_entity_tokens = [clean_token]
            current_entity_type = label[2:]  # æå–å®ä½“ç±»å‹
        elif label.startswith('I-') and current_entity_tokens:
            # ç»§ç»­å½“å‰å®ä½“ï¼ˆæ£€æŸ¥ç±»å‹æ˜¯å¦åŒ¹é…ï¼‰
            entity_type = label[2:]
            if entity_type == current_entity_type:
                current_entity_tokens.append(clean_token)
            else:
                # ç±»å‹ä¸åŒ¹é…ï¼Œç»“æŸå½“å‰å®ä½“
                if current_entity_tokens:
                    entity_text = ''.join(current_entity_tokens).replace('##', '')
                    if entity_text and len(entity_text) >= 2:
                        entities.append(entity_text)
                    current_entity_tokens = []
                    current_entity_type = None
        else:
            # Oæ ‡ç­¾ï¼Œç»“æŸå½“å‰å®ä½“
            if current_entity_tokens:
                entity_text = ''.join(current_entity_tokens).replace('##', '')
                if entity_text and len(entity_text) >= 2:
                    entities.append(entity_text)
                current_entity_tokens = []
                current_entity_type = None
    
    if current_entity_tokens:
        entity_text = ''.join(current_entity_tokens).replace('##', '')
        if entity_text and len(entity_text) >= 2:
            entities.append(entity_text)
    
    logger.info(f"\næå–çš„å®ä½“: {entities}")
    
    return entities


def generate_scientific_recommendations(data_stats, training_info, test_results):
    """åŸºäºå®é™…æ•°æ®ç”Ÿæˆç§‘å­¦çš„æ”¹è¿›å»ºè®®"""
    logger.info("\n" + "=" * 70)
    logger.info("æ¨¡å‹è¯Šæ–­ä¸æ”¹è¿›å»ºè®®")
    logger.info("=" * 70)
    
    recommendations = []
    
    # 1. æ•°æ®é‡åˆ†æ
    if data_stats:
        train_samples = data_stats.get('train_samples', 0)
        dev_samples = data_stats.get('dev_samples', 0)
        entity_types = data_stats.get('entity_types', 0)
        
        logger.info(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        logger.info(f"  è®­ç»ƒæ ·æœ¬: {train_samples:,} æ¡")
        logger.info(f"  éªŒè¯æ ·æœ¬: {dev_samples:,} æ¡")
        logger.info(f"  å®ä½“ç±»å‹: {entity_types} ç§")
        
        if train_samples < 1000:
            recommendations.append({
                'level': 'warning',
                'category': 'æ•°æ®é‡',
                'issue': f'è®­ç»ƒæ•°æ®é‡è¾ƒå°‘ï¼ˆ{train_samples}æ¡ï¼‰',
                'suggestion': 'å»ºè®®å¢åŠ è®­ç»ƒæ•°æ®åˆ°è‡³å°‘1,000æ¡ä»¥ä¸Šï¼Œä»¥æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›'
            })
        elif train_samples < 5000:
            recommendations.append({
                'level': 'info',
                'category': 'æ•°æ®é‡',
                'issue': f'è®­ç»ƒæ•°æ®é‡é€‚ä¸­ï¼ˆ{train_samples:,}æ¡ï¼‰',
                'suggestion': 'æ•°æ®é‡å……è¶³ï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–æ¨¡å‹ç»“æ„æˆ–è¶…å‚æ•°'
            })
        else:
            recommendations.append({
                'level': 'success',
                'category': 'æ•°æ®é‡',
                'issue': f'è®­ç»ƒæ•°æ®é‡å……è¶³ï¼ˆ{train_samples:,}æ¡ï¼‰',
                'suggestion': 'æ•°æ®é‡å……è¶³ï¼Œæ¨¡å‹æœ‰è‰¯å¥½çš„è®­ç»ƒåŸºç¡€'
            })
        
        if dev_samples == 0:
            recommendations.append({
                'level': 'warning',
                'category': 'éªŒè¯é›†',
                'issue': 'ç¼ºå°‘éªŒè¯é›†',
                'suggestion': 'å»ºè®®æ·»åŠ éªŒè¯é›†ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ'
            })
        elif dev_samples < train_samples * 0.1:
            recommendations.append({
                'level': 'info',
                'category': 'éªŒè¯é›†',
                'issue': f'éªŒè¯é›†æ¯”ä¾‹è¾ƒä½ï¼ˆ{dev_samples/train_samples*100:.1f}%ï¼‰',
                'suggestion': 'å»ºè®®éªŒè¯é›†æ¯”ä¾‹è¾¾åˆ°10-20%ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹æ€§èƒ½'
            })
    
    # 2. è®­ç»ƒä¿¡æ¯åˆ†æ
    if training_info:
        final_f1 = training_info.get('final_f1')
        final_accuracy = training_info.get('final_accuracy')
        epochs = training_info.get('epochs', 0)
        training_time = training_info.get('training_time')
        
        logger.info(f"\nğŸ¯ è®­ç»ƒæ€§èƒ½:")
        if final_f1:
            logger.info(f"  æœ€ç»ˆF1-Score: {final_f1:.4f} ({final_f1*100:.2f}%)")
        if final_accuracy:
            logger.info(f"  æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)")
        if epochs:
            logger.info(f"  è®­ç»ƒè½®æ•°: {epochs} epochs")
        if training_time:
            logger.info(f"  è®­ç»ƒæ—¶é—´: {training_time:.1f} ç§’ ({training_time/60:.1f} åˆ†é’Ÿ)")
        
        if final_f1:
            if final_f1 >= 0.98:
                recommendations.append({
                    'level': 'success',
                    'category': 'æ¨¡å‹æ€§èƒ½',
                    'issue': f'F1-Scoreä¼˜ç§€ï¼ˆ{final_f1*100:.2f}%ï¼‰',
                    'suggestion': 'æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼Œå·²è¾¾åˆ°ç”Ÿäº§çº§åˆ«æ ‡å‡†'
                })
            elif final_f1 >= 0.95:
                recommendations.append({
                    'level': 'info',
                    'category': 'æ¨¡å‹æ€§èƒ½',
                    'issue': f'F1-Scoreè‰¯å¥½ï¼ˆ{final_f1*100:.2f}%ï¼‰',
                    'suggestion': 'æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥å°è¯•è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥æå‡åˆ°98%ä»¥ä¸Š'
                })
            elif final_f1 >= 0.90:
                recommendations.append({
                    'level': 'warning',
                    'category': 'æ¨¡å‹æ€§èƒ½',
                    'issue': f'F1-Scoreä¸€èˆ¬ï¼ˆ{final_f1*100:.2f}%ï¼‰',
                    'suggestion': 'å»ºè®®å¢åŠ è®­ç»ƒæ•°æ®ã€è°ƒæ•´è¶…å‚æ•°æˆ–å¢åŠ è®­ç»ƒè½®æ•°'
                })
            else:
                recommendations.append({
                    'level': 'error',
                    'category': 'æ¨¡å‹æ€§èƒ½',
                    'issue': f'F1-Scoreè¾ƒä½ï¼ˆ{final_f1*100:.2f}%ï¼‰',
                    'suggestion': 'æ¨¡å‹æ€§èƒ½ä¸ç†æƒ³ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡ã€å¢åŠ è®­ç»ƒæ•°æ®é‡æˆ–é‡æ–°è®­ç»ƒ'
                })
        
        if epochs < 3:
            recommendations.append({
                'level': 'warning',
                'category': 'è®­ç»ƒè½®æ•°',
                'issue': f'è®­ç»ƒè½®æ•°è¾ƒå°‘ï¼ˆ{epochs}è½®ï¼‰',
                'suggestion': 'å»ºè®®å¢åŠ è®­ç»ƒè½®æ•°åˆ°5-10è½®ï¼Œç¡®ä¿æ¨¡å‹å……åˆ†å­¦ä¹ '
            })
        elif epochs > 10:
            recommendations.append({
                'level': 'info',
                'category': 'è®­ç»ƒè½®æ•°',
                'issue': f'è®­ç»ƒè½®æ•°è¾ƒå¤šï¼ˆ{epochs}è½®ï¼‰',
                'suggestion': 'æ³¨æ„ç›‘æ§éªŒè¯é›†æ€§èƒ½ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ'
            })
    
    # 3. æµ‹è¯•ç»“æœåˆ†æ
    if test_results:
        extracted_count = sum(1 for r in test_results if len(r) > 0)
        total_tests = len(test_results)
        
        logger.info(f"\nğŸ§ª æµ‹è¯•ç»“æœ:")
        logger.info(f"  æµ‹è¯•æ ·æœ¬æ•°: {total_tests}")
        logger.info(f"  æˆåŠŸæå–å®ä½“: {extracted_count}/{total_tests}")
        
        if extracted_count == 0:
            recommendations.append({
                'level': 'error',
                'category': 'å®ä½“æå–',
                'issue': 'æµ‹è¯•æ ·æœ¬ä¸­æœªæå–åˆ°ä»»ä½•å®ä½“',
                'suggestion': 'æ¨¡å‹å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹åŠ è½½ã€æ ‡ç­¾æ˜ å°„æˆ–é‡æ–°è®­ç»ƒ'
            })
        elif extracted_count < total_tests * 0.5:
            recommendations.append({
                'level': 'warning',
                'category': 'å®ä½“æå–',
                'issue': f'å®ä½“æå–æˆåŠŸç‡è¾ƒä½ï¼ˆ{extracted_count}/{total_tests}ï¼‰',
                'suggestion': 'å»ºè®®æ£€æŸ¥æµ‹è¯•æ–‡æœ¬æ˜¯å¦åŒ…å«è®­ç»ƒæ•°æ®ä¸­çš„å®ä½“ç±»å‹ï¼Œæˆ–å¢åŠ ç›¸å…³ç±»å‹çš„è®­ç»ƒæ•°æ®'
            })
    
    # 4. å®ä½“ç±»å‹åˆ†æ
    if data_stats and data_stats.get('entity_types', 0) > 0:
        entity_types_count = data_stats.get('entity_types', 0)
        if entity_types_count > 30:
            recommendations.append({
                'level': 'info',
                'category': 'å®ä½“ç±»å‹',
                'issue': f'å®ä½“ç±»å‹è¾ƒå¤šï¼ˆ{entity_types_count}ç§ï¼‰',
                'suggestion': 'å®ä½“ç±»å‹è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰ç±»å‹é‡å æˆ–å¯ä»¥åˆå¹¶çš„ç±»å‹'
            })
    
    # è¾“å‡ºå»ºè®®
    logger.info(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    
    if not recommendations:
        logger.info("  âœ… æ¨¡å‹çŠ¶æ€è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
    else:
        # æŒ‰çº§åˆ«æ’åºï¼šerror > warning > info > success
        level_order = {'error': 0, 'warning': 1, 'info': 2, 'success': 3}
        recommendations.sort(key=lambda x: level_order.get(x['level'], 4))
        
        for i, rec in enumerate(recommendations, 1):
            level_icon = {
                'error': 'âŒ',
                'warning': 'âš ï¸ ',
                'info': 'â„¹ï¸ ',
                'success': 'âœ…'
            }.get(rec['level'], 'â€¢')
            
            logger.info(f"\n  {i}. {level_icon} [{rec['category']}] {rec['issue']}")
            logger.info(f"     å»ºè®®: {rec['suggestion']}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 70)
    logger.info("NERæ¨¡å‹è¯Šæ–­")
    logger.info("=" * 70)
    
    # 1. åˆ†æè®­ç»ƒæ•°æ®
    data_stats = analyze_training_data()
    
    # 2. åˆ†æè®­ç»ƒæ—¥å¿—
    training_info = analyze_training_log()
    
    # 3. æµ‹è¯•æ¨¡å‹é¢„æµ‹
    model, tokenizer, device = load_model()
    test_results = []
    
    if model is None:
        logger.error("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè·³è¿‡é¢„æµ‹æµ‹è¯•")
        generate_scientific_recommendations(data_stats, training_info, [])
        return
    
    test_texts = [
        "é˜¿åˆ©Â·ä¼¯å…‹çº§é©±é€èˆ°è£…å¤‡æœ‰å®™æ–¯ç›¾ä½œæˆ˜ç³»ç»Ÿå’ŒAN/SPY-13Dç›¸æ§é˜µé›·è¾¾ï¼Œä¸»è¦ç”¨äºé˜²ç©ºä½œæˆ˜ã€‚",
        "è¯¥èˆ°è£…å¤‡äº†æˆ˜æ–§å·¡èˆªå¯¼å¼¹å’Œæ ‡å‡†ç³»åˆ—é˜²ç©ºå¯¼å¼¹ã€‚",
        "ç¾å›½æµ·å†›è®¡åˆ’å»ºé€ æœ±å§†æ²ƒå°”ç‰¹çº§é©±é€èˆ°ä½œä¸ºä¸‹ä¸€ä»£ä¸»åŠ›é©±é€èˆ°ã€‚"
    ]
    
    for text in test_texts:
        entities = test_prediction_detailed(text, model, tokenizer, device)
        test_results.append(entities)
    
    # 4. ç”Ÿæˆç§‘å­¦çš„æ”¹è¿›å»ºè®®
    generate_scientific_recommendations(data_stats, training_info, test_results)
    
    logger.info("\n" + "=" * 70)
    logger.info("è¯Šæ–­å®Œæˆ")
    logger.info("=" * 70)


if __name__ == "__main__":
    main()
